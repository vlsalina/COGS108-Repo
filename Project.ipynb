{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "26c8529e3b2e59be78d4aa19804373fc",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 3: Data Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19a89ebe76d5deeaebb3d494a20c2240",
     "grade": false,
     "grade_id": "important",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Important Reminders\n",
    "\n",
    "- Rename this file to 'A3_$####.ipynb', replacing with your unique ID (first letter of your last name, followed by the last 4 digits of your student ID number), before you submit it. Submit it to TritonED.\n",
    "- Do not change / update / delete any existing cells with 'assert' in them. These are the tests used to check your assignment. \n",
    "    - Changing these will be flagged for attempted cheating. \n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted file. \n",
    "    - This means passing all the tests you can see in the notebook here does not guarantee you have the right answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3e5ebfca3f2f8e75fb4d54102698bd77",
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "We have discussed in lecture the importance and the mechanics of protecting individuals privacy when they are included in datasets. \n",
    "\n",
    "One method to do so is the Safe Harbor Method. The Safe Harbour method specifies how to protect individual's identities by telling us which tells us which information to remove from a dataset in order to avoid accidently disclosing personal information. \n",
    "\n",
    "In this assignment, we will explore web scraping, which can often include personally identifiable information, how identity can be decoded from badly anonymized datasets, and also explore using Safe Harbour to anonymize datasets properly. \n",
    "\n",
    "The topics covered in this assignment are mainly covered in the 'DataGathering' and 'DataPrivacy&Anonymization' Tutorial notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ea20266c9be42b2fbdf472d6db1024dd",
     "grade": false,
     "grade_id": "cell-b169d37fcae03fbc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Installing new packages\n",
    "\n",
    "In the first part of the assignment we will understand how we can scrape the web for data. You have to use the Beautiful Soup library in Python for scraping the data. \n",
    "\n",
    "The library is not installed in Anaconda version, therefore to install a new library for Anaconda, we can use the conda package manager, which the cell below does for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dad55181dff84344120ab766c5b62d89",
     "grade": false,
     "grade_id": "cell-8a8f3952c7e67d7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to install beautifulsoup4\n",
    "#  You only need to do the installation once\n",
    "#    Once you have run it you can comment these two lines so that the cell doesn't execute everytime.\n",
    "\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e2ed7d7ab9a2d36798e407ed93e7e11",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d7cc48ec36a10ee8ce4301f4ad8068e",
     "grade": false,
     "grade_id": "import-code",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports - these provided for you. Do not import any other packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from geopy import geocoders\n",
    "from geopy.geocoders import Yandex\n",
    "import time \n",
    "\n",
    "\n",
    "g = Yandex()\n",
    "\n",
    "#for creating and showing histograms \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_location(address):\n",
    "    location = g.geocode(address)\n",
    "    return location\n",
    "\n",
    "#location = g.geocode('7800 BLOCK STALMER STREET')\n",
    "#location\n",
    "#print(location.address)\n",
    "#print((location.latitude, location.longitude))\n",
    "#print(location.raw)\n",
    "#(40.7407597+ 40.7413004)/2, (-73.9898715 + -73.9895014)/2\n",
    "#\"175 5th Avenue NYC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>Charge_Description_Orig</th>\n",
       "      <th>activityDate</th>\n",
       "      <th>BLOCK_ADDRESS</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>GRAND THEFT FROM PERSON</td>\n",
       "      <td>1/3/2018 16:30</td>\n",
       "      <td>7800  BLOCK STALMER STREET</td>\n",
       "      <td>92111.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>SELL LIQUOR TO MINOR (M)</td>\n",
       "      <td>9/23/2017 18:28</td>\n",
       "      <td>3200  BLOCK NORTH HARBOR DRIVE</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>DRUNK IN PUBLIC: ALCOHOL, DRUGS, COMBO OR TOLU...</td>\n",
       "      <td>10/6/2017 8:48</td>\n",
       "      <td>600  BLOCK CONVENTION WAY</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>DRUNK IN PUBLIC: ALCOHOL, DRUGS, COMBO OR TOLU...</td>\n",
       "      <td>10/11/2017 19:45</td>\n",
       "      <td>3600  BLOCK NORTH HARBOR DRIVE</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>POSS NARCOTIC CONTROLLED SUBS (M)</td>\n",
       "      <td>10/21/2017 23:36</td>\n",
       "      <td>100 W  BLOCK HARBOR DRIVE</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>POSSESS MARIJUANA 1 OZ OR  LESS WHILE DRIVING</td>\n",
       "      <td>1/8/2018 12:25</td>\n",
       "      <td>7600  BLOCK COPLEY PARK PLACE</td>\n",
       "      <td>92111.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>MANUFACTURE/SALE/POSSESS/ETC METAL KNUCKLES (M)</td>\n",
       "      <td>11/1/2017 17:15</td>\n",
       "      <td>3600  BLOCK NORTH HARBOR DRIVE</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>MINOR:KNOWINGLY OPER VEH W/CARRYING ALC (M)</td>\n",
       "      <td>11/4/2017 4:30</td>\n",
       "      <td>W LAUREL STREET / PACIFIC HIGHWAY</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>USE/UNDER INFL OF CONTROLLED SUBS (M)</td>\n",
       "      <td>11/12/2017 8:11</td>\n",
       "      <td>3100  BLOCK PACIFIC HIGHWAY</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HARBOR POLICE</td>\n",
       "      <td>BURGLARY (COMMERCIAL) (F)</td>\n",
       "      <td>9/1/2017 19:53</td>\n",
       "      <td>3700  BLOCK NORTH HARBOR DRIVE</td>\n",
       "      <td>92101.0</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          agency                            Charge_Description_Orig  \\\n",
       "0      SAN DIEGO                            GRAND THEFT FROM PERSON   \n",
       "1  HARBOR POLICE                           SELL LIQUOR TO MINOR (M)   \n",
       "2  HARBOR POLICE  DRUNK IN PUBLIC: ALCOHOL, DRUGS, COMBO OR TOLU...   \n",
       "3  HARBOR POLICE  DRUNK IN PUBLIC: ALCOHOL, DRUGS, COMBO OR TOLU...   \n",
       "4  HARBOR POLICE                  POSS NARCOTIC CONTROLLED SUBS (M)   \n",
       "5      SAN DIEGO      POSSESS MARIJUANA 1 OZ OR  LESS WHILE DRIVING   \n",
       "6  HARBOR POLICE    MANUFACTURE/SALE/POSSESS/ETC METAL KNUCKLES (M)   \n",
       "7  HARBOR POLICE        MINOR:KNOWINGLY OPER VEH W/CARRYING ALC (M)   \n",
       "8  HARBOR POLICE              USE/UNDER INFL OF CONTROLLED SUBS (M)   \n",
       "9  HARBOR POLICE                          BURGLARY (COMMERCIAL) (F)   \n",
       "\n",
       "       activityDate                      BLOCK_ADDRESS  ZipCode  community  \n",
       "0    1/3/2018 16:30         7800  BLOCK STALMER STREET  92111.0  SAN DIEGO  \n",
       "1   9/23/2017 18:28     3200  BLOCK NORTH HARBOR DRIVE  92101.0  SAN DIEGO  \n",
       "2    10/6/2017 8:48          600  BLOCK CONVENTION WAY  92101.0  SAN DIEGO  \n",
       "3  10/11/2017 19:45     3600  BLOCK NORTH HARBOR DRIVE  92101.0  SAN DIEGO  \n",
       "4  10/21/2017 23:36          100 W  BLOCK HARBOR DRIVE  92101.0  SAN DIEGO  \n",
       "5    1/8/2018 12:25      7600  BLOCK COPLEY PARK PLACE  92111.0  SAN DIEGO  \n",
       "6   11/1/2017 17:15     3600  BLOCK NORTH HARBOR DRIVE  92101.0  SAN DIEGO  \n",
       "7    11/4/2017 4:30  W LAUREL STREET / PACIFIC HIGHWAY  92101.0  SAN DIEGO  \n",
       "8   11/12/2017 8:11        3100  BLOCK PACIFIC HIGHWAY  92101.0  SAN DIEGO  \n",
       "9    9/1/2017 19:53     3700  BLOCK NORTH HARBOR DRIVE  92101.0  SAN DIEGO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = pd.read_csv('Crime_Data.csv', encoding = 'ISO-8859-1')\n",
    "stuff2 = stuff[:10]\n",
    "stuff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "date = []\n",
    "christmas = []\n",
    "for x in stuff['activityDate']:\n",
    "    if(x.find('2018') == -1):\n",
    "        date.append(x[:x.find('2017')+ 4])\n",
    "    else:\n",
    "        date.append(x[:x.find('2018')+ 4])\n",
    "date\n",
    "stuff['date'] = date\n",
    "#stuff = stuff['agency', 'Charge_Description_Orig' , 'activityDate', 'date', 'BLOCK_ADDRESS', 'ZipCode', 'community']\n",
    "\n",
    "#loop through stuff to find all crimes that happened on christmas and add them to a list.\n",
    "for i, row in enumerate(stuff.values):\n",
    "    if(row[6].find('12/25/2017') != -1):\n",
    "        christmas.append(row)\n",
    "\n",
    "#same idea as above loop but used to check total crimes on any day. you can play around with the specifc day by changing the value\n",
    "# in \"('12/30/2017')\"\n",
    "for i, row in enumerate(stuff.values):\n",
    "    if(row[6].find('12/30/2017') != -1):\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-16-2870c8800545>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-2870c8800545>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#location = find_location('7800 BLOCK STALMER STREET')\n",
    "#stuff2.BLOCK_ADDRESS.apply(find_location)\n",
    "#s = stuff2.BLOCK_ADDRESS\n",
    "#for x in range(0, s.size):\n",
    "#print(g.geocode(s[0]))\n",
    "#time.sleep(1.5)\n",
    "#print(g.geocode(s[0]))\n",
    "\n",
    "loc_coordinates = []\n",
    "loc_address = []\n",
    "\n",
    "for address in stuff2.BLOCK_ADDRESS:\n",
    "    inputAddress = address\n",
    "    location = g.geocode(inputAddress)\n",
    "    if (location is not None):\n",
    "        print(location\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function that finds the street that the crimes commited by cleaning it of anything other than the street name\n",
    "def standardize_address(string):\n",
    "    \n",
    "    string = string.lower()\n",
    "    string = string.strip()\n",
    "    string = ' '+ string\n",
    "    \n",
    "    #gets rid of numbers in address so we can see crimes in a street\n",
    "    string = ''.join(index for index in string if not index.isdigit())\n",
    "    \n",
    "    string = string.replace('block', '')\n",
    "    string = string.replace('drive', '')\n",
    "    string = string.replace('highway', '')\n",
    "    string = string.replace('way', '')\n",
    "    string = string.replace('place', '')\n",
    "    string = string.replace('street', '')\n",
    "    \n",
    "    string = string.replace('north', '')\n",
    "    string = string.replace('south', '')\n",
    "    string = string.replace('east', '')\n",
    "    string = string.replace('west', '')\n",
    "    string = string.replace(' n ', '')\n",
    "    string = string.replace(' s ', '')\n",
    "    string = string.replace(' e ', '')\n",
    "    string = string.replace(' w ', '')\n",
    "    \n",
    "    string = string.strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shonak\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21cc1d3cda0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAD8CAYAAAD5YZq3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creates street name column that only contains the names of the streets\n",
    "stuff2['street name'] = stuff2.BLOCK_ADDRESS.apply(standardize_address)\n",
    "\n",
    "#creates a histogram to see which streets have most crimes in form of a bar chart\n",
    "stuff2['street name'].value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2258dd8460e82dd9ba05790b392c2170",
     "grade": false,
     "grade_id": "cell-25153cbdcaad4068",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Web Scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1879df607edbde1394ed6b304ba0a2c7",
     "grade": false,
     "grade_id": "cell-76ae256b5f7132b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Scraping Rules\n",
    "\n",
    "1) If you are using another organizations website for scraping, make sure to check the website's terms & conditions. \n",
    "\n",
    "2) Do not request data from the website too aggressively (quickly) with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "\n",
    "3) The layout of a website may change from time to time. Because of this, if you're scraping website, make sure to revisit the site and rewrite your code as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4176af1f7152bcb4deff540099f3cfd9",
     "grade": false,
     "grade_id": "cell-f5423577b9902c1c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will help you understand the permission issues related to accessing a page\n",
    "# Uncomment the two lines, run them, see what error you get, comment them again\n",
    "\n",
    "page_source = requests.get('http://www.aflcio.org/Legislation-and-Politics/Legislative-Alerts')\n",
    "page_soup = BeautifulSoup(page_source.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d4fed909c257ed14ed7cf6306ee015f2",
     "grade": false,
     "grade_id": "cell-164e625a3cd53f8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### What is the error that you got, and why did you get it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d7239e9d93ef503e59cabbee1d3e5481",
     "grade": true,
     "grade_id": "cell-ac79813190d0715c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a30f65a5cf189bcbb356196ea240d9a5",
     "grade": false,
     "grade_id": "cell-889693bf71daf7c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1a) Web Scrape\n",
    "# We will first retrieve the contents on a page and examine them a bit.\n",
    "\n",
    "# Make a variable called 'wiki', that stores the following URL (as a string):\n",
    "#  'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population'\n",
    "# To open the URL you can use 'requests.get' as shown in the cell above. Call this variable 'page'\n",
    "# After that use BeautifulSoup Library to open the URL and assign it to an object called 'soup'\n",
    "\n",
    "wiki = 'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population'\n",
    "page = requests.get(wiki)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#raise NotImpementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "88991ab92634826735078f6cba9eb0f1",
     "grade": true,
     "grade_id": "cell-52fad88c14b5f276",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert wiki\n",
    "assert page\n",
    "assert soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3625afdb3bb344958bba5e5266366ece",
     "grade": false,
     "grade_id": "cell-4d0a0b26ed667fe0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List of U.S. states and territories by population - Wikipedia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1b) Checking Scrape Contents\n",
    "\n",
    "# Extract the title from the page and save it in a variable called 'title_page'. \n",
    "#  Make sure you extract it as a string.\n",
    "# To do so, you have to use the soup object created in the above cell. \n",
    "#  Hint: from your soup variable, you can access this with '.title.string'\n",
    "# Make sure you print out and check the contents of 'title_page'. \n",
    "#  Note that it should not have any tags (such as '<title>' included in it).\n",
    "\n",
    "title_page = soup.title.string\n",
    "title_page\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ccf61e856e952c8a889f6c03f334321",
     "grade": true,
     "grade_id": "cell-25e2c00e1488f142",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert title_page\n",
    "assert isinstance(title_page, str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "915ab52cbc25de35a1bd5b74bdb1ec95",
     "grade": false,
     "grade_id": "cell-8da7172c1da665fe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1c) Extracting Tables\n",
    "\n",
    "# In order to extract the data we want, we'll start with extracting a data table of interest. \n",
    "#  Note that you can see this table by going to look at the link we scraped.\n",
    "# Use the soup object and call a method called find, which will and extract the first table in scraped webpage. \n",
    "#  Note: you need to search for the name 'table', and set the 'class_' argument as 'wikitable sortable'.\n",
    "\n",
    "right_table = soup.find('table', class_ = 'wikitable sortable')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "410073a57bc12f34587a7795bbbd852b",
     "grade": true,
     "grade_id": "cell-6a079fac89c3332c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert right_table\n",
    "assert isinstance(right_table, bs4.element.Tag)\n",
    "assert right_table.name == 'table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c2d4694252bd5b0f9d973cedba0946e8",
     "grade": false,
     "grade_id": "cell-6219dfad1bd6ba7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract the data from the table into lists.\n",
    "#  Note: This code provided for you. Do read through it and try to see how it works.\n",
    "\n",
    "lst_a, lst_b, lst_c = [], [], []\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "    \n",
    "    cells = row.findAll('td')\n",
    "    \n",
    "    # Skips rows that aren't 10 columns long (like the heading)\n",
    "    if len(cells) != 10:\n",
    "        continue\n",
    "\n",
    "    # This catches when the name cells stops having a link\n",
    "    #  and ends, skipping the last (summary rows)\n",
    "    try:\n",
    "        lst_a.append(cells[2].find('a').text)\n",
    "        lst_b.append(cells[4].find(text=True))\n",
    "        lst_c.append(cells[5].find(text=True))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4c75c47a485558ac3428c3773830b2ea",
     "grade": false,
     "grade_id": "cell-3b72a498799ef251",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1d) Collecting into a dataframe\n",
    "\n",
    "# Create a dataframe 'my_df' and add the data from the lists above to it. \n",
    "#  'lst_a' is the state or territory name. Set the column name as 'State', and make this the index\n",
    "#  'lst_b' is the population estimate. Add it to the dataframe, and set the column name as 'Population Estimate'\n",
    "#  'lst_c' is the census population. Add it to the dataframe, and set the column name as 'Census Population'\n",
    "\n",
    "my_df = pd.DataFrame({'State': lst_a}).set_index('State')\n",
    "my_df['Population Estimate'] = lst_b\n",
    "my_df['Census Population'] = lst_c\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2513c3a8257e82e2789c4709dbf70488",
     "grade": true,
     "grade_id": "cell-406fc7a4b3d93852",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance (my_df, pd.DataFrame)\n",
    "assert my_df.index.name == 'State'\n",
    "assert list(my_df.columns) == ['Population Estimate', 'Census Population']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "04bb731afd119f67f7b280a0c684420b",
     "grade": false,
     "grade_id": "cell-552f1cceb6530fef",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1e) Using the data\n",
    "# What is the Population Estimate of California? Save this answer to a variable called 'calif_pop'\n",
    "# Notes\n",
    "#  Extract this value programmatically from your dataframe (as in, don't set it explicitly, as 'cf = 123')\n",
    "#    You can use '.loc' to extract a particular value from a dataframe.\n",
    "#  The data in your dataframe will be strings - that's fine, leave them as strings (don't typecast).\n",
    "\n",
    "calif_pop = my_df.loc['California', 'Population Estimate']\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21a3ae96ee9a898e0e1cba4371c9dd11",
     "grade": true,
     "grade_id": "cell-00910bf76609b48e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert calif_pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "486c6798edf0e518657ce5e65244601c",
     "grade": false,
     "grade_id": "p1-title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Identifying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4296e9303d0b9997e5919024b4dc1734",
     "grade": false,
     "grade_id": "p1-desc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Data Files:\n",
    "- anon_user_dat.json\n",
    "- employee_info.json\n",
    "\n",
    "You will first be working with a file called 'anon_user_dat.json'. This file that contains information about some (fake) Tinder users. When creating an account, each Tinder user was asked to provide their first name, last name, work email (to verify the disclosed workplace), age, gender, phone # and zip code. Before releasing this data, a data scientist cleaned the data to protect the privacy of Tinder's users by removing the obvious personal identifiers: phone #, zip code, and IP address. However, the data scientist chose to keep each users' email addresses because when they visually skimmed a couple of the email addresses none of them seemed to have any of the user's actual names in them. This is where the data scientist made a huge mistake!\n",
    "\n",
    "We will take advantage of having the work email addresses by finding the employee information of different companies and matching that employee information with the information we have, in order to identify the names of the secret Tinder users!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4cc07f1511b85ba053b9bbc64f9b49c6",
     "grade": false,
     "grade_id": "1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a3347763392a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m# Load the json file into a pandas dataframe. Call it 'df_personal'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_personal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'anon_user_dat.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;31m#raise NotImplementedError()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Shonak\\Anaconda3\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines)\u001b[0m\n\u001b[1;32m    232\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    233\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'series'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Shonak\\Anaconda3\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Shonak\\Anaconda3\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 519\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# 2a) Load in the 'cleaned' data \n",
    "\n",
    "# Load the json file into a pandas dataframe. Call it 'df_personal'.\n",
    "\n",
    "df_personal = pd.read_json('anon_user_dat.json')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61909bf161ee3e26eaca9c2f1a52fd41",
     "grade": true,
     "grade_id": "1a-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_personal, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7fb39c47226cd7f94cc245d51747b746",
     "grade": false,
     "grade_id": "1b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2b) Check the first 10 emails \n",
    "\n",
    "# Save the first 10 emails to a Series, and call it 'sample_emails'. \n",
    "# You should then and print out this Series. \n",
    "# The purpose of this is to get a sense of how these work emails are structured\n",
    "#   and how we could possibly extract where each anonymous user seems to work.\n",
    "\n",
    "sample_emails = df_personal['email'][0:10]\n",
    "#sample_emails = df_personal['email'].head(n=10)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e5d7c945a4d2cc76ba068baf15641d43",
     "grade": true,
     "grade_id": "1b-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(sample_emails, pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b61be355079651582175dccbace705a5",
     "grade": false,
     "grade_id": "1c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2c) Extract the Company Name From the Email \n",
    "\n",
    "# Create a function with the following specifications:\n",
    "#   Function Name: extract_company\n",
    "#   Purpose: to extract the company of the email \n",
    "#          (i.e., everything after the @ sign but before the .)\n",
    "#   Parameter(s): email (string)\n",
    "#   Returns: The extracted part of the email (string)\n",
    "#   Hint: This should take 1 line of code. Look into the find('') method. \n",
    "#\n",
    "# You can start with this outline:\n",
    "#   def extract_company(email):\n",
    "#      return \n",
    "#\n",
    "# Example Usage: \n",
    "#   extract_company(\"larhe@uber.com\") should return \"uber\"\n",
    "#   extract_company(“ds@cogs.edu”) should return “cogs”\n",
    "\n",
    "\n",
    "def extract_company(email):\n",
    "    return email[email.find('@')+1 : email.find('.', email.find('@')+1)]\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06225023bd1fad52a5f8e084753af2fb",
     "grade": true,
     "grade_id": "1c-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert extract_company(\"gshoreson0@seattletimes.com\") == \"seattletimes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2ef7d9e3ecb79343b5b35d3aa70891a8",
     "grade": false,
     "grade_id": "info",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "With a little bit of basic sleuthing (aka googling) and web-scraping (aka selectively reading in html code) it turns out that you've been able to collect information about all the present employees/interns of the companies you are interested in. Specifically, on each company website, you have found the name, gender, and age of its employees. You have saved that info in employee_info.json and plan to see if, using this new information, you can match the Tinder accounts to actual names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ad3fb36e40e8bb9b629a4d6830c71729",
     "grade": false,
     "grade_id": "1d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2d) Load in employee data \n",
    "\n",
    "# Load the json file into a pandas dataframe. Call it 'df_employee'.\n",
    "\n",
    "df_employee = pd.read_json('employee_info.json')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd93c56e6879c7b8b50c7317bd3e1246",
     "grade": true,
     "grade_id": "1d-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_employee, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "fc07ea1ae1be13b991d48f428cac7b37",
     "grade": false,
     "grade_id": "1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2e) Match the employee name with company, age, gender \n",
    "\n",
    "# Create a function with the following specifications:\n",
    "#   Function name: employee_matcher\n",
    "#   Purpose: to match the employee name with the provided company, age, and gender\n",
    "#   Parameter(s): company (string), age (int), gender (string)\n",
    "#   Returns: The employee first_name and last_name like this: return first_name, last_name \n",
    "#   Note: If there are multiple employees that fit the same description, first_name and \n",
    "#         last_name should return a list of all possible first names and last name\n",
    "#         i.e., ['Desmund', 'Kelby'], ['Shepley', 'Tichner']\n",
    "#\n",
    "# Hint:\n",
    "# There are many different ways to code this.\n",
    "# 1) An unelegant solution is to loop through df_employee \n",
    "#    and for each data item see if the company, age, and gender match\n",
    "#    i.e., for i in range(0, len(df_employee)):\n",
    "#              if (company == df_employee.ix[i,'company']):\n",
    "#\n",
    "# However! The solution above is very inefficient and long, \n",
    "# so you should try to look into this:\n",
    "# 2) Google the df.loc method: It extracts pieces of the dataframe\n",
    "#    if it fulfills a certain condition.\n",
    "#    i.e., df_employee.loc[df_employee['company'] == company]\n",
    "#    If you need to convert your pandas data series into a list,\n",
    "#    you can do list(result) where result is a pandas \"series\"\n",
    "# \n",
    "# You can start with this outline:\n",
    "#   def employee_matcher(company, age, gender):\n",
    "#      return first_name, last_name\n",
    "\n",
    "def employee_matcher(company,age,gender):\n",
    "    first_name,last_name = list(),list()\n",
    "    new_df = df_employee.loc[df_employee['company']==company].loc[df_employee['age']==age].loc[df_employee['gender']==gender]\n",
    "    if new_df.size !=0:\n",
    "        first_name,last_name = list(new_df['first_name']), list(new_df['last_name'])\n",
    "    return first_name, last_name\n",
    "#employee_matcher(\"google\", 41, \"Male\")\n",
    "#print(employee_matcher(\"jalbum\", 29, \"Female\"),df_employee.loc[df_employee['age'] == 29])\n",
    "#print(employee_matcher(\"\", 62, \"Male\"),df_employee.loc[df_employee['first_name'] == 'Desmund'])\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f713cf00c84495d3bea5ba76d0f7e6a",
     "grade": true,
     "grade_id": "1e-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert employee_matcher(\"google\", 41, \"Male\") == (['Maxwell'], ['Jorio'])\n",
    "assert employee_matcher(\"salon\", 47, \"Female\") == (['Elenore'], ['Gravett'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "eb565b364684e43f855d5ff731384879",
     "grade": false,
     "grade_id": "1f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2f) Extract all the private data \n",
    "\n",
    "# - Create 2 empty lists called 'first_names' and 'last_names'\n",
    "# - Loop through all the people we are trying to identify in df_personal\n",
    "# - Call the extract_company function (i.e., extract_company(df_personal.ix[i, 'email']) )\n",
    "# - Call the employee_matcher function \n",
    "# - Append the results of employee_matcher to the appropriate lists (first_names and last_names)\n",
    "\n",
    "first_names, last_names = list(), list()\n",
    "for i in range(df_personal['email'].size):\n",
    "#    company = extract_company(df_personal.loc[i]['email'])\n",
    "    company = extract_company(df_personal.ix[i, 'email'])\n",
    "    #a, b = employee_matcher(company, df_personal.loc[i]['age'],df_personal.loc[i]['gender'])\n",
    "    a, b = employee_matcher(company, df_personal.ix[i, 'age'],df_personal.ix[i,'gender'])\n",
    "    first_names.append(a)\n",
    "    last_names.append(b)\n",
    "    #i = i +1\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60add6c068758eb6abcaa30879d2b7af",
     "grade": true,
     "grade_id": "1f-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert first_names[45:50]== [['Justino'], ['Tadio'], ['Kennith'], ['Cedric'], ['Amargo']]\n",
    "assert last_names[45:50] == [['Corro'], ['Blackford'], ['Milton'], ['Yggo'], ['Grigor']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "797556598e2b8c2406f949635a108850",
     "grade": false,
     "grade_id": "1g",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 2g) Add the names to the original 'secure' dataset! \n",
    "\n",
    "# We have done this last step for you below, all you need to do is run this cell.\n",
    "# For your own personal enjoyment, you should also print out\n",
    "#   the new df_personal with the identified people. \n",
    "\n",
    "df_personal['first_name'] = first_names\n",
    "df_personal['last_name'] = last_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "220e03ead46597189f618c88f0088bcc",
     "grade": false,
     "grade_id": "wrap-p1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We have now just discovered the 'anonymous' identities of all the registered Tinder users...awkward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "975e9008d46096fe811a216ea5f2b0d3",
     "grade": false,
     "grade_id": "p2-title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Anonymize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28f7733eb649c467c1e05df6a0287439",
     "grade": false,
     "grade_id": "p2-desc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You are hopefully now convinced that with some seemingly harmless data a hacker can pretty easily discover the identities of certain users. Thus, we will now clean the original Tinder data ourselves according to the Safe Harbor Method in order to make sure that it has been *properly* cleaned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "89e65ce9092dc3ace07ed9f7e32b2fc1",
     "grade": false,
     "grade_id": "2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3a) Load in personal data \n",
    "\n",
    "# Load the user_dat.json file into a pandas dataframe. Call it 'df_users'.\n",
    "# Note: You might find that using the same method as A2 (or above) leads to an error.\n",
    "# The file has a slightly different organization. \n",
    "#   Try googling the error and finding the fix for it.\n",
    "# Hint: you can still use 'pd.read_json', you just need to add another argument.\n",
    "\n",
    "df_users = pd.read_json('user_dat.json', lines = True)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ec60d4634be90d7f87fd0bd248755cd",
     "grade": true,
     "grade_id": "2a-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_users, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "912a843843c85ea7007bfa6fe034ecb0",
     "grade": false,
     "grade_id": "2b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3b) Drop personal attributes \n",
    "\n",
    "# Remove any personal information, following the Safe Harbour method.\n",
    "# Based on the Safe Harbour method, remove any columns from df_users that contain personal information.\n",
    "#   Note that details on the Safe Harbour method are covered in the Tutorials.\n",
    "\n",
    "df_users = df_users.drop(['email', 'first_name', 'ip_address', 'last_name', 'phone'], axis = 1)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aaaa4402b823f36919d4953dcd89ebba",
     "grade": true,
     "grade_id": "2b-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_users.columns) == 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2055761795183edb7258b03b76270898",
     "grade": false,
     "grade_id": "2c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3c) Drop ages that are above 90 \n",
    "\n",
    "# Safe Harbour rule C:\n",
    "#   Drop all the rows which have age greater than 90 from df_users\n",
    "\n",
    "#df_users['age'] = df_users.loc[df_users['age'] <= 90].dropna()\n",
    "\n",
    "df_users = df_users[df_users.age <=90]\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0bf95b9f32e8c6f695d2850814459daa",
     "grade": true,
     "grade_id": "2c-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_users.shape == (993, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f4745cc6348949495135886a90078d9d",
     "grade": false,
     "grade_id": "2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3d) Load in zip code data \n",
    "\n",
    "# Load the zip_pop.csv file into a (different) pandas dataframe. Call it 'df_zip'.\n",
    "# Note that the zip data should be read in as strings, not ints, as would be the default. \n",
    "# In read_csv, use the parameter 'dtype' to specify to read 'zip' as str, and 'population' as int.\n",
    "\n",
    "df_zip = pd.read_csv('zip_pop.csv', dtype = {'zip': str, 'population': int})\n",
    "df_zip.drop_duplicates('zip', inplace=True)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78a50c8e93d6577339c9611bdd7eaaa8",
     "grade": true,
     "grade_id": "2d-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_zip, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9cc339bd36e3b2c3813c6852608d87cc",
     "grade": false,
     "grade_id": "2e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3e) Sort zipcodes into \"Geographic Subdivision\" \n",
    "\n",
    "# The Safe Harbour Method applies to \"Geographic Subdivisions\"\n",
    "#   as opposed to each zipcode itself. \n",
    "# Geographic Subdivision:\n",
    "#   All areas which share the first 3 digits of a zip code\n",
    "#\n",
    "# Count the total population for each geographic subdivision\n",
    "# Warning: you have to be savy with a dictionary here\n",
    "# To understand how a dictionary works, check the section materials,\n",
    "#   use google and go to discussion sections!\n",
    "#\n",
    "# Instructions: \n",
    "# - Create an empty dictionary: zip_dict = {}\n",
    "# - Loop through all the zip_codes in df_zip\n",
    "# - Create a dictionary key for the first 3 digits of a zip_code in zip_dict\n",
    "# - Continually add population counts to the key that contains the \n",
    "#     same first 3 digits of the zip code\n",
    "#\n",
    "# To extract the population you will find this code useful:\n",
    "#   population = list(df_zip.loc[df_zip['zip'] == zip_code]['population'])\n",
    "# To extract the first 3 digits of a zip_code you will find this code useful:\n",
    "#   int(str(zip_code)[:3])\n",
    "#\n",
    "# Note: this code may take some time (many seconds, up to a minute or two) to run\n",
    "\n",
    "zip_dict = {}\n",
    "for i, r in df_zip.iterrows():\n",
    "    zip_code = r['zip']\n",
    "    population = r['population']\n",
    "    zip_key = int(zip_code[:3])\n",
    "    if zip_key not in zip_dict.keys():\n",
    "        zip_dict[zip_key] = population\n",
    "    else:\n",
    "        zip_dict[zip_key] += population\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2bd97a39d94617052c6bb3cc8c5bd497",
     "grade": true,
     "grade_id": "2e-tests",
     "locked": true,
     "points": 1.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(zip_dict, dict)\n",
    "assert zip_dict[100] == 1502501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4dcaab99a0cd491db53cc2842f3d750f",
     "grade": false,
     "grade_id": "2f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 3f) Explain this code excerpt \n",
    "# Note: you do not have to use this line of code at this point in the assignmnet.\n",
    "#  It is one of the lines provided to you in 2e. Here, just write a quick comment on what it does. \n",
    "\n",
    "# In the cell below, explain in words what what the following line of code is doing:\n",
    "population = list(df_zip.loc[df_zip['zip'] == zip_code]['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cc98e43035f0175d3f82fe6a94dc5f58",
     "grade": true,
     "grade_id": "2f-write",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Population is a list made up of the column 'population' from the dataframe created when trying to locate where in df_zip that the 'zip' is equal to the zip_code variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "621d2ead4f68903eaa2ddadbf4f64459",
     "grade": false,
     "grade_id": "2g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3g) Masking the Zip Codes \n",
    "\n",
    "# In this part, you should write a for loop, updating the df_users dataframe.\n",
    "# Go through each user, and update their zip-code, to Safe Harbour specifications:\n",
    "#   If the user is from a zip code for the which the\n",
    "#     \"Geographic Subdivision\" is less than equal to 20000:\n",
    "#        - Change the zip code to 0 \n",
    "#   Otherwise:\n",
    "#         - Change the zip code to be only the first 3 numbers of the full zip cide\n",
    "# Do all this re-writting the zip_code columns of the 'df_users' DataFrame\n",
    "#\n",
    "# Hints:\n",
    "#  - This will be several lines of code, looping through the DataFrame, \n",
    "#      getting each zip code, checking the geographic subdivision with \n",
    "#      the population in zip_dict, and settig the zip_code accordingly. \n",
    "\n",
    "for i,r in df_users.iterrows():\n",
    "    zip_code = r['zip']\n",
    "    zip_key = int(str(zip_code)[:3]) \n",
    "    #geo_sub = zip_code(zip_key)\n",
    "    if (zip_key not in zip_dict.keys()) or (zip_dict[zip_key]< 20000):\n",
    "        df_users.loc[i, 'zip'] = 0\n",
    "    else:\n",
    "        df_users.loc[i, 'zip'] = zip_key\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96ef0f83802b7b170238228b68be36e1",
     "grade": true,
     "grade_id": "2g-tests",
     "locked": true,
     "points": 1.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_users) == 993\n",
    "assert sum(df_users.zip == 0) == 7\n",
    "assert df_users.loc[671, 'zip'] == 359\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a0313df0a86a0d1c0f762fadfa8fc80d",
     "grade": false,
     "grade_id": "2h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3h) Save out the properly anonymized data to json file \n",
    "\n",
    "# Save out df_users as a json file, called 'real_anon_user_dat.json'\n",
    "\n",
    "df_users.to_json(path_or_buf = 'real_anon_user_dat.json')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f1b809a9d61919bc0dd68fda1aedc1b",
     "grade": true,
     "grade_id": "2h-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pd.read_json('real_anon_user_dat.json'), pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d2d93ad8046edf965c498ec0bf27f765",
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Congrats, you're done! The users identities are much more protected now. \n",
    "\n",
    "Submit this notebook file to TritonED."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
