{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "58294f2f6954788b5eb81260b7a6c9e0",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 4: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97e7001c934ed18e214f39459a1faae8",
     "grade": false,
     "grade_id": "instr",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Important\n",
    "- Rename this file to 'A4_$####.ipynb', replacing with your unique ID (first letter of your last name, followed by the last 4 digits of your student ID number), before you submit it. Submit it to TritonED.\n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted assignment for grading.\n",
    "    - This means passing all the tests you can see in the notebook here does not guarantee you have the right answer!\n",
    "    - In particular many of the tests you can see simply check that the right variable names exist. Hidden tests check the actual values. \n",
    "        - It is up to you to check the values, and make sure they seem reasonable.\n",
    "- A reminder to restart the kernel and re-run the code as a first line check if things seem to go weird.\n",
    "    - For example, note that some cells can only be run once, because they re-write a variable (for example, your dataframe), and change it in a way that means a second execution will fail. \n",
    "    - Also, running some cells out of order might change the dataframe in ways that may cause an error, which can be fixed by re-running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8883e4175fe2e4f82313d9b1067dd17e",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports -  These are all you need for the assignment: do not import additional packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "\n",
    "# Note: the statsmodels import may print out a 'FutureWarning'. Thats fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e9e188e9e9979614153ec1edf0d2328",
     "grade": false,
     "grade_id": "notes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Notes - Assignment Outline\n",
    "\n",
    "Parts 1-6 of this assignment are modelled on being a minimal example of a project notebook. \n",
    "\n",
    "This mimics, and gets you working with, something like what you will need for your final project.\n",
    "\n",
    "Parts 7 & 8 and break from the project narrative, and are OPTIONAL (UNGRADED). \n",
    "\n",
    "They serve instead as a couple of quick one-offs to get you working with some other methods that might be useful to incorporate into your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4108eea07e694d4000a605cc79b8c111",
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Data: the responses collected from a survery of the COGS 108 class. \n",
    "- There are 417 observations in the data, covering 10 different 'features'.\n",
    "\n",
    "Research Question: Do students in different majors have different heights?\n",
    "\n",
    "Background: Physical height has previously shown to correlate with career choice, and career success. More recently it has been demonstrated that these correlations can actually be explained by height in high school, as opposed to height in adulthood (1). It is currently unclear whether height correlates with choice of major in university. \n",
    "\n",
    "Reference: 1) http://economics.sas.upenn.edu/~apostlew/paper/pdf/short.pdf\n",
    "\n",
    "Hypothesis: We hypothesize that there will be a relation between height and chosen major. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7200cff9f3b9c62aeea15349f1fa693a",
     "grade": false,
     "grade_id": "part1-title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Load & Clean the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb2074c24750cdd719937a8d9cb05275",
     "grade": false,
     "grade_id": "cell-9b83334ad8ec954e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Fixing messy data makes up a large amount of the work of being a Data Scientist. \n",
    "\n",
    "The real world produces messy measurements and it is your job to find ways to standardize your data such that you can make useful analyses out of it. \n",
    "\n",
    "In this section, you will learn, and practice, how to successfully deal with unclean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0c59be4ffc6e1cca7df0f283118fe854",
     "grade": false,
     "grade_id": "cell-252b5cfd5c8ceff2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1a) Import datafile 'COGS108_IntroQuestionnaireData.csv' into a DataFrame called 'df'.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df = pd.read_csv('COGS108_IntroQuestionnaireData.csv')\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7add1c3ae3aa4bfba8bec17181c99cd",
     "grade": true,
     "grade_id": "1a_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73fd18848ab2cbaf83624544b3b5224b",
     "grade": false,
     "grade_id": "cell-61a420950f1db378",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>What year (in school) are you?</th>\n",
       "      <th>What is your major?</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your height?</th>\n",
       "      <th>What is your weight?</th>\n",
       "      <th>What is your eye color?</th>\n",
       "      <th>Were you born in California?</th>\n",
       "      <th>What is your favorite flavor of ice cream?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/9/2018 14:49:40</td>\n",
       "      <td>4</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>5'8\"</td>\n",
       "      <td>147</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/9/2018 14:49:45</td>\n",
       "      <td>3</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>5'8</td>\n",
       "      <td>150</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies and Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/9/2018 14:49:45</td>\n",
       "      <td>Third</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>178cm</td>\n",
       "      <td>74kg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Matcha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/9/2018 14:49:45</td>\n",
       "      <td>2</td>\n",
       "      <td>Cogs HCI</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>5’8</td>\n",
       "      <td>133</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies and Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2018 14:49:47</td>\n",
       "      <td>3</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>5'8\"</td>\n",
       "      <td>160</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies n' Cream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Timestamp What year (in school) are you? What is your major?  \\\n",
       "0  1/9/2018 14:49:40                              4   Cognitive Science   \n",
       "1  1/9/2018 14:49:45                              3   Cognitive Science   \n",
       "2  1/9/2018 14:49:45                          Third    Computer Science   \n",
       "3  1/9/2018 14:49:45                              2            Cogs HCI   \n",
       "4  1/9/2018 14:49:47                              3    Computer Science   \n",
       "\n",
       "  How old are you? What is your gender? What is your height?  \\\n",
       "0               21                 Male                 5'8\"   \n",
       "1               20                 Male                  5'8   \n",
       "2               21                 Male                178cm   \n",
       "3               20                 Male                  5’8   \n",
       "4               20                 Male                 5'8\"   \n",
       "\n",
       "  What is your weight? What is your eye color? Were you born in California?  \\\n",
       "0                  147                   Brown                          Yes   \n",
       "1                  150                   Brown                          Yes   \n",
       "2                 74kg                   Black                          Yes   \n",
       "3                  133                   Brown                          Yes   \n",
       "4                  160                   Brown                          Yes   \n",
       "\n",
       "  What is your favorite flavor of ice cream?  \n",
       "0                                    Vanilla  \n",
       "1                          Cookies and Cream  \n",
       "2                                     Matcha  \n",
       "3                          Cookies and Cream  \n",
       "4                           Cookies n' Cream  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21c928cef2bc165a4ff6f7bb8373c252",
     "grade": false,
     "grade_id": "cell-17404c0fbde64360",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Those column names are a bit excessive, so first let's rename them - code provided below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1913e22a14a497b8aabadad763a146fe",
     "grade": false,
     "grade_id": "cell-d9fa719279b7cb33",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Renaming the columns of the dataframe\n",
    "df.columns = [\"timestamp\", \"year\", \"major\", \"age\", \"gender\", \"height\",\n",
    "              \"weight\", \"eye_color\", \"born_in_CA\", \"favorite_icecream\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "890ff2e4ee3e1e31319e33dbf37f1b0a",
     "grade": false,
     "grade_id": "cell-cf1899b1f00333c8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Pandas has a very useful function for detecting missing data. This function is called 'isnull()'. \n",
    "\n",
    "If you have a dataframe called 'df', then calling 'df.isnull()' will return another dataframe of the same size as 'df' where every cell is either True of False. \n",
    "\n",
    "Each True or False is the answer to the question 'is the data in this cell null?'. So, False, means the cell is not null (and therefore, does have data). True means the cell is null (does not have data).\n",
    "\n",
    "This function is very useful because it allows us to find missing data very quickly in our dataframe. As an example, consider the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5bd1f30b8443e94e0ade52162fdcf25",
     "grade": false,
     "grade_id": "cell-e7d9fb27de2854f0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>born_in_CA</th>\n",
       "      <th>favorite_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp   year  major    age  gender  height  weight  eye_color  \\\n",
       "0      False  False  False  False   False   False   False      False   \n",
       "1      False  False  False  False   False   False   False      False   \n",
       "2      False  False  False  False   False   False   False      False   \n",
       "3      False  False  False  False   False   False   False      False   \n",
       "4      False  False  False  False   False   False   False      False   \n",
       "\n",
       "   born_in_CA  favorite_icecream  \n",
       "0       False              False  \n",
       "1       False              False  \n",
       "2       False              False  \n",
       "3       False              False  \n",
       "4       False              False  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows of the 'isnull' dataframe\n",
    "df.isnull().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03107618506e96decd6c8083dbf3cd92",
     "grade": false,
     "grade_id": "cell-dbf2938a926e4835",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>born_in_CA</th>\n",
       "      <th>favorite_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   year  major    age  gender  height  weight  eye_color  \\\n",
       "48      False  False  False  False   False   False   False      False   \n",
       "49      False   True  False  False   False    True    True      False   \n",
       "\n",
       "    born_in_CA  favorite_icecream  \n",
       "48       False              False  \n",
       "49       False              False  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you print out more, and scroll down, you'll see some rows with missing data. For example:\n",
    "df.isnull().iloc[48:50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "72ed7b86b2dc5b1ad802aa9e5c6c742a",
     "grade": false,
     "grade_id": "cell-30d70e19a2fdf110",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp            1/9/2018 14:50:12\n",
       "year                               NaN\n",
       "major                          Cog Sci\n",
       "age                                 21\n",
       "gender                          Female\n",
       "height                             NaN\n",
       "weight                             NaN\n",
       "eye_color                        Brown\n",
       "born_in_CA                         Yes\n",
       "favorite_icecream            Chocolate\n",
       "Name: 49, dtype: object"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check an example, row 49, in which an entry has missing data\n",
    "df.iloc[49, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97f71909d96adc52d88d95c450775bcf",
     "grade": false,
     "grade_id": "cell-ab125f3306fbd956",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Granted, the example above is not very informative. As you can see, the output of 'isnull()' is a dataframe where the values at each cell is either True or False. Most cells have the value of 'False'. We expect this to be the case since most people gave out answers to each question in our survey. \n",
    "\n",
    "However, some rows such as row 49 show that some people chose not to answer certain questions. In the case of row 49, it seems that someone did not give out an answer for 'What year (in school) are you?'\n",
    "\n",
    "However, what if wanted to use 'isnull()' to see all rows where our dataframe 'df' has missing values? In other words, what if we want to see the ACTUAL rows with missing values instead of this dataframe with True or False cells. For that, we need to write the following line of code:\n",
    "<br>\n",
    "<br>\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6c860cd121b99639859a6f4190b0440",
     "grade": false,
     "grade_id": "cell-e3440fa7cdd2647d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>born_in_CA</th>\n",
       "      <th>favorite_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1/9/2018 14:50:00</td>\n",
       "      <td>senior</td>\n",
       "      <td>math&amp;econ</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>173</td>\n",
       "      <td>130</td>\n",
       "      <td>black</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1/9/2018 14:50:05</td>\n",
       "      <td>3rd</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1/9/2018 14:50:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cog Sci</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1/9/2018 14:50:14</td>\n",
       "      <td>3rd</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>5ft 2in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1/9/2018 14:50:16</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>Cognitive Science - Design and Interaction</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>5'5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Chubby hubby ben and jerrys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1/9/2018 14:50:16</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1/9/2018 14:50:23</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>5'11</td>\n",
       "      <td>155 lb</td>\n",
       "      <td>dark brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1/9/2018 14:50:25</td>\n",
       "      <td>Third</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>Green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1/9/2018 14:50:26</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5'2\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mint chip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1/9/2018 14:50:36</td>\n",
       "      <td>2018</td>\n",
       "      <td>computer science</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1/9/2018 14:50:39</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>5 ft 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>Green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1/9/2018 14:50:41</td>\n",
       "      <td>Second</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies and Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1/9/2018 14:50:43</td>\n",
       "      <td>Fourth</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sea salt cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1/9/2018 14:50:45</td>\n",
       "      <td>Second</td>\n",
       "      <td>Cogs sci</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1/9/2018 14:50:50</td>\n",
       "      <td>Second</td>\n",
       "      <td>Computer science</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1/9/2018 14:51:05</td>\n",
       "      <td>Second</td>\n",
       "      <td>Bioengineering</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.7 m</td>\n",
       "      <td>70kg</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1/9/2018 14:51:10</td>\n",
       "      <td>4th</td>\n",
       "      <td>Cogs Sci HCI</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5 feet 4 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mint chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1/9/2018 14:51:13</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>175cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Mint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1/9/2018 14:51:22</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>168cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dark Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1/9/2018 14:51:33</td>\n",
       "      <td>4</td>\n",
       "      <td>Molecular Biology</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1/9/2018 14:51:36</td>\n",
       "      <td>2nd</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>5-10</td>\n",
       "      <td>160 pounds</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1/9/2018 14:51:40</td>\n",
       "      <td>3</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1/9/2018 14:52:06</td>\n",
       "      <td>4th</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5’7’’</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1/9/2018 14:52:07</td>\n",
       "      <td>4</td>\n",
       "      <td>Cognitive Science - Machine Learning and Neura...</td>\n",
       "      <td>21</td>\n",
       "      <td>Nonbinary</td>\n",
       "      <td>5'5\"</td>\n",
       "      <td>120 lbs.</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1/9/2018 14:52:10</td>\n",
       "      <td>2</td>\n",
       "      <td>EECS</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>150</td>\n",
       "      <td>chocolate pudding</td>\n",
       "      <td>Yes</td>\n",
       "      <td>👌👀👌👀👌👀👌👀👌👀 good shit go౦ԁ sHit👌 thats ✔ some g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1/9/2018 14:52:30</td>\n",
       "      <td>1</td>\n",
       "      <td>MathCS</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>5 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Matcha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1/9/2018 14:52:37</td>\n",
       "      <td>second year</td>\n",
       "      <td>computer science</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1/9/2018 14:53:13</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5'8\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1/9/2018 14:55:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>68in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp         year  \\\n",
       "29   1/9/2018 14:50:00       senior   \n",
       "38   1/9/2018 14:50:05          3rd   \n",
       "49   1/9/2018 14:50:12          NaN   \n",
       "58   1/9/2018 14:50:14          3rd   \n",
       "66   1/9/2018 14:50:16    Sophomore   \n",
       "67   1/9/2018 14:50:16            2   \n",
       "83   1/9/2018 14:50:23       Senior   \n",
       "91   1/9/2018 14:50:25        Third   \n",
       "92   1/9/2018 14:50:26            4   \n",
       "133  1/9/2018 14:50:36         2018   \n",
       "140  1/9/2018 14:50:39       Senior   \n",
       "150  1/9/2018 14:50:41       Second   \n",
       "159  1/9/2018 14:50:43       Fourth   \n",
       "168  1/9/2018 14:50:45       Second   \n",
       "181  1/9/2018 14:50:50       Second   \n",
       "232  1/9/2018 14:51:05       Second   \n",
       "241  1/9/2018 14:51:10          4th   \n",
       "249  1/9/2018 14:51:13            2   \n",
       "264  1/9/2018 14:51:22            4   \n",
       "285  1/9/2018 14:51:33            4   \n",
       "293  1/9/2018 14:51:36          2nd   \n",
       "304  1/9/2018 14:51:40            3   \n",
       "352  1/9/2018 14:52:06          4th   \n",
       "354  1/9/2018 14:52:07            4   \n",
       "357  1/9/2018 14:52:10            2   \n",
       "376  1/9/2018 14:52:30            1   \n",
       "381  1/9/2018 14:52:37  second year   \n",
       "402  1/9/2018 14:53:13            4   \n",
       "413  1/9/2018 14:55:00            3   \n",
       "\n",
       "                                                 major  age     gender  \\\n",
       "29                                           math&econ   20     female   \n",
       "38                                Computer Engineering   21     Female   \n",
       "49                                             Cog Sci   21     Female   \n",
       "58                                    Computer Science   20     Female   \n",
       "66          Cognitive Science - Design and Interaction   19     Female   \n",
       "67                                    Computer Science   19       Male   \n",
       "83                                    Computer Science   22       Male   \n",
       "91                                    Computer Science   21     Female   \n",
       "92                                    Computer Science   21     Female   \n",
       "133                                   computer science   22       male   \n",
       "140                               Chemical Engineering   25     Female   \n",
       "150                                  Cognitive Science   19     Female   \n",
       "159                                  Cognitive Science   21     Female   \n",
       "168                                           Cogs sci   20     female   \n",
       "181                                   Computer science   18       Male   \n",
       "232                                    Bioengineering    20       Male   \n",
       "241                                       Cogs Sci HCI   21     Female   \n",
       "249                                  Computer Science    20       Male   \n",
       "264                                   Computer Science   21     Female   \n",
       "285                                 Molecular Biology    21        NaN   \n",
       "293                               Computer Engineering  NaN       Male   \n",
       "304                                   Computer Science   20       Male   \n",
       "352                                  Cognitive Science   21     Female   \n",
       "354  Cognitive Science - Machine Learning and Neura...   21  Nonbinary   \n",
       "357                                               EECS   19        NaN   \n",
       "376                                             MathCS   18          M   \n",
       "381                                   computer science   19       male   \n",
       "402                                   Computer Science   21     Female   \n",
       "413                                   Computer Science   20          M   \n",
       "\n",
       "          height      weight          eye_color born_in_CA  \\\n",
       "29           173         130              black         No   \n",
       "38           NaN         NaN              Brown         No   \n",
       "49           NaN         NaN              Brown        Yes   \n",
       "58       5ft 2in         NaN              brown         No   \n",
       "66           5'5         NaN              Brown         No   \n",
       "67           NaN         170              Brown        Yes   \n",
       "83          5'11      155 lb         dark brown         No   \n",
       "91           NaN         NaN              Black         No   \n",
       "92          5'2\"         NaN              Brown        Yes   \n",
       "133          NaN         NaN              brown         No   \n",
       "140       5 ft 3         NaN              Black         No   \n",
       "150          NaN         NaN                NaN        Yes   \n",
       "159          NaN         NaN              Black        Yes   \n",
       "168          178         NaN              brown         No   \n",
       "181          NaN         NaN              Brown         No   \n",
       "232        1.7 m        70kg              Black         No   \n",
       "241  5 feet 4 in         NaN              brown        Yes   \n",
       "249        175cm         NaN              Brown         No   \n",
       "264        168cm         NaN         Dark Brown        Yes   \n",
       "285          NaN         NaN                NaN        NaN   \n",
       "293         5-10  160 pounds              Brown        Yes   \n",
       "304          NaN         NaN              Brown        Yes   \n",
       "352        5’7’’         NaN              Brown         No   \n",
       "354         5'5\"    120 lbs.             Brown         Yes   \n",
       "357         6.21         150  chocolate pudding        Yes   \n",
       "376         5 10         NaN              Brown         No   \n",
       "381          NaN         NaN                NaN         No   \n",
       "402         5'8\"         NaN              Brown        Yes   \n",
       "413         68in         NaN              Brown        Yes   \n",
       "\n",
       "                                     favorite_icecream  \n",
       "29                                                 NaN  \n",
       "38                                                 NaN  \n",
       "49                                           Chocolate  \n",
       "58                                   cookies and cream  \n",
       "66                         Chubby hubby ben and jerrys  \n",
       "67                                           Chocolate  \n",
       "83                                                 NaN  \n",
       "91                                           Green tea  \n",
       "92                                           Mint chip  \n",
       "133                                                NaN  \n",
       "140                                          Green tea  \n",
       "150                                  Cookies and Cream  \n",
       "159                         Sea salt cookies and cream  \n",
       "168                                          green tea  \n",
       "181                                  Cookies and cream  \n",
       "232                                                NaN  \n",
       "241                                     Mint chocolate  \n",
       "249                                               Mint  \n",
       "264                                            Vanilla  \n",
       "285                                          Green Tea  \n",
       "293                                                NaN  \n",
       "304                                         Strawberry  \n",
       "352                                                NaN  \n",
       "354                                                NaN  \n",
       "357  👌👀👌👀👌👀👌👀👌👀 good shit go౦ԁ sHit👌 thats ✔ some g...  \n",
       "376                                             Matcha  \n",
       "381                                         strawberry  \n",
       "402                                         Strawberry  \n",
       "413                                                NaN  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1b) Find all rows that have missing data in them.\n",
    "# Save the ouput, as a dataframe, into a variable called 'rows_to_drop'.\n",
    "# In other words, copy over and use the line of code that we gave out in the cell above.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "rows_to_drop = df[df.isnull().any(axis=1)]\n",
    "rows_to_drop\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1aafb0f66a16e716faddffd24aec72e2",
     "grade": true,
     "grade_id": "cell-1fe471d877a8f859",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(rows_to_drop, pd.DataFrame)\n",
    "assert rows_to_drop.shape == (29, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9af8e15ddd1aa6c06b6fe6848f0dc1b1",
     "grade": false,
     "grade_id": "cell-edcb7dd3662adfe8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>born_in_CA</th>\n",
       "      <th>favorite_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1/9/2018 14:50:00</td>\n",
       "      <td>senior</td>\n",
       "      <td>math&amp;econ</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>173</td>\n",
       "      <td>130</td>\n",
       "      <td>black</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1/9/2018 14:50:05</td>\n",
       "      <td>3rd</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1/9/2018 14:50:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cog Sci</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1/9/2018 14:50:14</td>\n",
       "      <td>3rd</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>5ft 2in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1/9/2018 14:50:16</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>Cognitive Science - Design and Interaction</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>5'5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Chubby hubby ben and jerrys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1/9/2018 14:50:16</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1/9/2018 14:50:23</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>5'11</td>\n",
       "      <td>155 lb</td>\n",
       "      <td>dark brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1/9/2018 14:50:25</td>\n",
       "      <td>Third</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>Green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1/9/2018 14:50:26</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5'2\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mint chip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1/9/2018 14:50:36</td>\n",
       "      <td>2018</td>\n",
       "      <td>computer science</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1/9/2018 14:50:39</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>5 ft 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>Green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1/9/2018 14:50:41</td>\n",
       "      <td>Second</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies and Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1/9/2018 14:50:43</td>\n",
       "      <td>Fourth</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sea salt cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1/9/2018 14:50:45</td>\n",
       "      <td>Second</td>\n",
       "      <td>Cogs sci</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1/9/2018 14:50:50</td>\n",
       "      <td>Second</td>\n",
       "      <td>Computer science</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1/9/2018 14:51:05</td>\n",
       "      <td>Second</td>\n",
       "      <td>Bioengineering</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.7 m</td>\n",
       "      <td>70kg</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1/9/2018 14:51:10</td>\n",
       "      <td>4th</td>\n",
       "      <td>Cogs Sci HCI</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5 feet 4 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mint chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1/9/2018 14:51:13</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>175cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Mint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1/9/2018 14:51:22</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>168cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dark Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1/9/2018 14:51:33</td>\n",
       "      <td>4</td>\n",
       "      <td>Molecular Biology</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1/9/2018 14:51:36</td>\n",
       "      <td>2nd</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>5-10</td>\n",
       "      <td>160 pounds</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1/9/2018 14:51:40</td>\n",
       "      <td>3</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1/9/2018 14:52:06</td>\n",
       "      <td>4th</td>\n",
       "      <td>Cognitive Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5’7’’</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1/9/2018 14:52:07</td>\n",
       "      <td>4</td>\n",
       "      <td>Cognitive Science - Machine Learning and Neura...</td>\n",
       "      <td>21</td>\n",
       "      <td>Nonbinary</td>\n",
       "      <td>5'5\"</td>\n",
       "      <td>120 lbs.</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1/9/2018 14:52:10</td>\n",
       "      <td>2</td>\n",
       "      <td>EECS</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>150</td>\n",
       "      <td>chocolate pudding</td>\n",
       "      <td>Yes</td>\n",
       "      <td>👌👀👌👀👌👀👌👀👌👀 good shit go౦ԁ sHit👌 thats ✔ some g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1/9/2018 14:52:30</td>\n",
       "      <td>1</td>\n",
       "      <td>MathCS</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>5 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Matcha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1/9/2018 14:52:37</td>\n",
       "      <td>second year</td>\n",
       "      <td>computer science</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1/9/2018 14:53:13</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>5'8\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1/9/2018 14:55:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>68in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp         year  \\\n",
       "29   1/9/2018 14:50:00       senior   \n",
       "38   1/9/2018 14:50:05          3rd   \n",
       "49   1/9/2018 14:50:12          NaN   \n",
       "58   1/9/2018 14:50:14          3rd   \n",
       "66   1/9/2018 14:50:16    Sophomore   \n",
       "67   1/9/2018 14:50:16            2   \n",
       "83   1/9/2018 14:50:23       Senior   \n",
       "91   1/9/2018 14:50:25        Third   \n",
       "92   1/9/2018 14:50:26            4   \n",
       "133  1/9/2018 14:50:36         2018   \n",
       "140  1/9/2018 14:50:39       Senior   \n",
       "150  1/9/2018 14:50:41       Second   \n",
       "159  1/9/2018 14:50:43       Fourth   \n",
       "168  1/9/2018 14:50:45       Second   \n",
       "181  1/9/2018 14:50:50       Second   \n",
       "232  1/9/2018 14:51:05       Second   \n",
       "241  1/9/2018 14:51:10          4th   \n",
       "249  1/9/2018 14:51:13            2   \n",
       "264  1/9/2018 14:51:22            4   \n",
       "285  1/9/2018 14:51:33            4   \n",
       "293  1/9/2018 14:51:36          2nd   \n",
       "304  1/9/2018 14:51:40            3   \n",
       "352  1/9/2018 14:52:06          4th   \n",
       "354  1/9/2018 14:52:07            4   \n",
       "357  1/9/2018 14:52:10            2   \n",
       "376  1/9/2018 14:52:30            1   \n",
       "381  1/9/2018 14:52:37  second year   \n",
       "402  1/9/2018 14:53:13            4   \n",
       "413  1/9/2018 14:55:00            3   \n",
       "\n",
       "                                                 major  age     gender  \\\n",
       "29                                           math&econ   20     female   \n",
       "38                                Computer Engineering   21     Female   \n",
       "49                                             Cog Sci   21     Female   \n",
       "58                                    Computer Science   20     Female   \n",
       "66          Cognitive Science - Design and Interaction   19     Female   \n",
       "67                                    Computer Science   19       Male   \n",
       "83                                    Computer Science   22       Male   \n",
       "91                                    Computer Science   21     Female   \n",
       "92                                    Computer Science   21     Female   \n",
       "133                                   computer science   22       male   \n",
       "140                               Chemical Engineering   25     Female   \n",
       "150                                  Cognitive Science   19     Female   \n",
       "159                                  Cognitive Science   21     Female   \n",
       "168                                           Cogs sci   20     female   \n",
       "181                                   Computer science   18       Male   \n",
       "232                                    Bioengineering    20       Male   \n",
       "241                                       Cogs Sci HCI   21     Female   \n",
       "249                                  Computer Science    20       Male   \n",
       "264                                   Computer Science   21     Female   \n",
       "285                                 Molecular Biology    21        NaN   \n",
       "293                               Computer Engineering  NaN       Male   \n",
       "304                                   Computer Science   20       Male   \n",
       "352                                  Cognitive Science   21     Female   \n",
       "354  Cognitive Science - Machine Learning and Neura...   21  Nonbinary   \n",
       "357                                               EECS   19        NaN   \n",
       "376                                             MathCS   18          M   \n",
       "381                                   computer science   19       male   \n",
       "402                                   Computer Science   21     Female   \n",
       "413                                   Computer Science   20          M   \n",
       "\n",
       "          height      weight          eye_color born_in_CA  \\\n",
       "29           173         130              black         No   \n",
       "38           NaN         NaN              Brown         No   \n",
       "49           NaN         NaN              Brown        Yes   \n",
       "58       5ft 2in         NaN              brown         No   \n",
       "66           5'5         NaN              Brown         No   \n",
       "67           NaN         170              Brown        Yes   \n",
       "83          5'11      155 lb         dark brown         No   \n",
       "91           NaN         NaN              Black         No   \n",
       "92          5'2\"         NaN              Brown        Yes   \n",
       "133          NaN         NaN              brown         No   \n",
       "140       5 ft 3         NaN              Black         No   \n",
       "150          NaN         NaN                NaN        Yes   \n",
       "159          NaN         NaN              Black        Yes   \n",
       "168          178         NaN              brown         No   \n",
       "181          NaN         NaN              Brown         No   \n",
       "232        1.7 m        70kg              Black         No   \n",
       "241  5 feet 4 in         NaN              brown        Yes   \n",
       "249        175cm         NaN              Brown         No   \n",
       "264        168cm         NaN         Dark Brown        Yes   \n",
       "285          NaN         NaN                NaN        NaN   \n",
       "293         5-10  160 pounds              Brown        Yes   \n",
       "304          NaN         NaN              Brown        Yes   \n",
       "352        5’7’’         NaN              Brown         No   \n",
       "354         5'5\"    120 lbs.             Brown         Yes   \n",
       "357         6.21         150  chocolate pudding        Yes   \n",
       "376         5 10         NaN              Brown         No   \n",
       "381          NaN         NaN                NaN         No   \n",
       "402         5'8\"         NaN              Brown        Yes   \n",
       "413         68in         NaN              Brown        Yes   \n",
       "\n",
       "                                     favorite_icecream  \n",
       "29                                                 NaN  \n",
       "38                                                 NaN  \n",
       "49                                           Chocolate  \n",
       "58                                   cookies and cream  \n",
       "66                         Chubby hubby ben and jerrys  \n",
       "67                                           Chocolate  \n",
       "83                                                 NaN  \n",
       "91                                           Green tea  \n",
       "92                                           Mint chip  \n",
       "133                                                NaN  \n",
       "140                                          Green tea  \n",
       "150                                  Cookies and Cream  \n",
       "159                         Sea salt cookies and cream  \n",
       "168                                          green tea  \n",
       "181                                  Cookies and cream  \n",
       "232                                                NaN  \n",
       "241                                     Mint chocolate  \n",
       "249                                               Mint  \n",
       "264                                            Vanilla  \n",
       "285                                          Green Tea  \n",
       "293                                                NaN  \n",
       "304                                         Strawberry  \n",
       "352                                                NaN  \n",
       "354                                                NaN  \n",
       "357  👌👀👌👀👌👀👌👀👌👀 good shit go౦ԁ sHit👌 thats ✔ some g...  \n",
       "376                                             Matcha  \n",
       "381                                         strawberry  \n",
       "402                                         Strawberry  \n",
       "413                                                NaN  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You need to run & read this cell - but don't have to add any code:\n",
    "#\n",
    "# Real world data is messy. As an example of it, we consider the data shown in rows_to_drop (below).\n",
    "# If you've done everything correctly so far, you should see an unexpected response with emojis at index 357.\n",
    "# These types of responses, although funny, are hard to parse when dealing with big datasets. \n",
    "# We'll learn about solutions to these types of problems in the upcoming cells\n",
    "\n",
    "rows_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35a61b42d4bec2b37486bac122577778",
     "grade": false,
     "grade_id": "cell-3315a8862e040169",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In the cell below, briefly explain below how 'df[df.isnull().any(axis=1)]' works, in a couple sentences. \n",
    "\n",
    "Include an explanation of what 'any(axis=1)' means and how it affects the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "507d6774c06f53efa226e23350b30983",
     "grade": true,
     "grade_id": "cell-fa3000a3bcda221f",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The code 'df[df.isnull().any(axis=1)]' looks for null values in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "26f1e8a5b1b804d300f970d1f3878dfd",
     "grade": false,
     "grade_id": "1c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>born_in_CA</th>\n",
       "      <th>favorite_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1/9/2018 14:50:01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>69.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1/9/2018 14:50:14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>62.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>cookies and cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1/9/2018 14:50:16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>65.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Chubby hubby ben and jerrys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1/9/2018 14:50:23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>71.00</td>\n",
       "      <td>155.0</td>\n",
       "      <td>dark brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1/9/2018 14:50:26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>62.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mint chip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1/9/2018 14:50:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>62.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>blue</td>\n",
       "      <td>No</td>\n",
       "      <td>mint chocolate chip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1/9/2018 14:50:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "      <td>70.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>brown</td>\n",
       "      <td>No</td>\n",
       "      <td>mint chocolate chip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1/9/2018 14:50:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>69.03</td>\n",
       "      <td>140.0</td>\n",
       "      <td>black</td>\n",
       "      <td>No</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1/9/2018 14:50:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>64.00</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Super dark brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Yogurt or any fruity flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1/9/2018 14:50:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data science</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>73.00</td>\n",
       "      <td>215.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>McVoytek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1/9/2018 14:50:35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>70.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate Carmel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1/9/2018 14:50:39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>25</td>\n",
       "      <td>female</td>\n",
       "      <td>63.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>Green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1/9/2018 14:50:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Peanut butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1/9/2018 14:50:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>72.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>I don't like ice cream.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1/9/2018 14:50:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>69.00</td>\n",
       "      <td>145.0</td>\n",
       "      <td>Hazel</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1/9/2018 14:51:05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BIO</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>66.30</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1/9/2018 14:51:10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mint chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1/9/2018 14:51:13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>68.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Mint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1/9/2018 14:51:22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>65.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dark Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1/9/2018 14:51:25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>69.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Orange Sherbet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1/9/2018 14:51:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>70.00</td>\n",
       "      <td>145.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1/9/2018 14:51:49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>70.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1/9/2018 14:52:06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>67.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1/9/2018 14:52:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>72.00</td>\n",
       "      <td>179.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1/9/2018 14:53:13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1/9/2018 14:53:23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1/9/2018 14:55:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1/9/2018 14:55:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>69.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>No</td>\n",
       "      <td>Chocolate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  year         major  age  gender  height  weight  \\\n",
       "30   1/9/2018 14:50:01   4.0       COMPSCI   22    male   69.03     NaN   \n",
       "58   1/9/2018 14:50:14   3.0       COMPSCI   20  female   62.00     NaN   \n",
       "66   1/9/2018 14:50:16   2.0        COGSCI   19  female   65.00     NaN   \n",
       "83   1/9/2018 14:50:23   4.0       COMPSCI   22    male   71.00   155.0   \n",
       "92   1/9/2018 14:50:26   4.0       COMPSCI   21  female   62.00     NaN   \n",
       "95   1/9/2018 14:50:27   NaN        COGSCI   22  female   62.00   119.0   \n",
       "103  1/9/2018 14:50:28   NaN       COMPSCI   21    male   70.00   160.0   \n",
       "105  1/9/2018 14:50:29   NaN       COMPSCI   23    male   69.03   140.0   \n",
       "109  1/9/2018 14:50:30   NaN        COGSCI   21  female   64.00   125.0   \n",
       "116  1/9/2018 14:50:32   NaN  data science   19    male   73.00   215.0   \n",
       "125  1/9/2018 14:50:35   3.0        COGSCI   20    male   70.00     NaN   \n",
       "140  1/9/2018 14:50:39   4.0          CHEM   25  female   63.00     NaN   \n",
       "153  1/9/2018 14:50:42   1.0       COMPSCI   18    male   68.00     NaN   \n",
       "188  1/9/2018 14:50:51   NaN       COMPSCI   20    male   72.00     NaN   \n",
       "201  1/9/2018 14:50:56   NaN       COMPSCI   19    male   69.00   145.0   \n",
       "232  1/9/2018 14:51:05   2.0           BIO   20    male   66.30   140.0   \n",
       "241  1/9/2018 14:51:10   4.0        COGSCI   21  female   64.00     NaN   \n",
       "249  1/9/2018 14:51:13   2.0       COMPSCI   20    male   68.25     NaN   \n",
       "264  1/9/2018 14:51:22   4.0       COMPSCI   21  female   65.52     NaN   \n",
       "268  1/9/2018 14:51:25   2.0       COMPSCI   19    male   69.00     NaN   \n",
       "295  1/9/2018 14:51:37   NaN        COGSCI   22    male   70.00   145.0   \n",
       "323  1/9/2018 14:51:49   2.0        COGSCI   18    male   70.00     NaN   \n",
       "352  1/9/2018 14:52:06   4.0        COGSCI   21  female   67.00     NaN   \n",
       "364  1/9/2018 14:52:15   NaN        COGSCI   20    male   72.00   179.0   \n",
       "402  1/9/2018 14:53:13   4.0       COMPSCI   21  female   68.00     NaN   \n",
       "404  1/9/2018 14:53:23   2.0       COMPSCI   19    male   64.00     NaN   \n",
       "413  1/9/2018 14:55:00   3.0       COMPSCI   20    male   68.00     NaN   \n",
       "414  1/9/2018 14:55:52   NaN       COMPSCI   28    male   69.00   170.0   \n",
       "\n",
       "            eye_color born_in_CA            favorite_icecream  \n",
       "30              brown         No                         rose  \n",
       "58              brown         No            cookies and cream  \n",
       "66              Brown         No  Chubby hubby ben and jerrys  \n",
       "83         dark brown         No                          NaN  \n",
       "92              Brown        Yes                    Mint chip  \n",
       "95               blue         No          mint chocolate chip  \n",
       "103             brown         No          mint chocolate chip  \n",
       "105             black         No                   Strawberry  \n",
       "109  Super dark brown         No  Yogurt or any fruity flavor  \n",
       "116             Brown         No                     McVoytek  \n",
       "125             Brown        Yes             Chocolate Carmel  \n",
       "140             Black         No                    Green tea  \n",
       "153            Brown         Yes                Peanut butter  \n",
       "188             Brown         No      I don't like ice cream.  \n",
       "201             Hazel        Yes                    Chocolate  \n",
       "232             Black         No                          NaN  \n",
       "241             brown        Yes               Mint chocolate  \n",
       "249             Brown         No                         Mint  \n",
       "264        Dark Brown        Yes                      Vanilla  \n",
       "268             Brown        Yes               Orange Sherbet  \n",
       "295             Brown         No                       Coffee  \n",
       "323             Brown        Yes                   Strawberry  \n",
       "352             Brown         No                          NaN  \n",
       "364             Black         No                   Strawberry  \n",
       "402             Brown        Yes                   Strawberry  \n",
       "404             Brown        Yes                    Chocolate  \n",
       "413             Brown        Yes                          NaN  \n",
       "414            Brown          No                   Chocolate   "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1c) Drop any rows with missing data, but only for the columns 'major', 'height', 'gender' and 'age'. \n",
    "#  These will be the data of primary interest for our analyses, so we drop missing data here. \n",
    "#    Note that there are other missing data (in other rows) but this is fine for our analyses, so we keep them. \n",
    "#  To do this, ese the pandas 'dropna' method, inplace, using the 'subset' arguments to specify columns.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df.dropna(axis=0, subset=['major','height','gender','age'], inplace=True)\n",
    "#df\n",
    "#df = df[df.isnull().any(axis=1)]\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "86dea5fe5a032081fc368bc718663738",
     "grade": true,
     "grade_id": "1c_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df.shape == (404, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "017719326fee592ae77e06c4fba0c0a2",
     "grade": false,
     "grade_id": "cell-ec7c94363479cbcb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we have to standardize the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c72f67e2c04325e14059d3f5a05c68c2",
     "grade": false,
     "grade_id": "cell-4121a97eb3f8c1f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cognitive Science', 'Computer Science', 'Cogs HCI',\n",
       "       'Cognitive Science w/ a specialization in Computation',\n",
       "       'International Studies', 'Computer Engineering', 'computer science',\n",
       "       'Chemical Engineering / Literature Writing',\n",
       "       'Cognitive Science w/ Specialization in Human Computer Interaction',\n",
       "       'Cognitive Science-- Machine Learning and Neural Computation ',\n",
       "       'Cse', 'Cognitive Science - Design and Interaction',\n",
       "       'cognitive science', 'CSE', 'Cog sci design interaction', 'Math CS',\n",
       "       'Electrical Engineering', 'math&econ',\n",
       "       'Cognitive Science spec/ HCI', 'Cognitive science', 'Math-CS',\n",
       "       'Data Science', 'Cognitive science ', 'Cognitive Science ',\n",
       "       'Math - CS ', 'Cognitive Science Human Computer Interaction',\n",
       "       'Cognitive Science with specialization in HCI ',\n",
       "       'Cognitive Science (HCI)', 'Probability & Statistics', 'Cog Sci',\n",
       "       'Cognitive Science - Machine Learning',\n",
       "       'Mathematics-computer science', 'Computer science ',\n",
       "       'Computer Science-Bioinformatics', 'Computer Scientist',\n",
       "       'Cognitive science (HCI)',\n",
       "       'Cogsci specializing in machine learning and neural computation ',\n",
       "       'cognitive science with specialization in machine learning and neural computation',\n",
       "       'Cogntive Science with emphasis on Clinical Aspects',\n",
       "       'Computer Science ', 'Cognitive Science ML&NC major, CSE minor',\n",
       "       'math-cs', 'Cognitive Science: Human-Computer Interaction',\n",
       "       'Political Science',\n",
       "       'Cognitive Science with a specialization in Neuroscience',\n",
       "       'Molecular Biology', 'Mathematics-Computer Science',\n",
       "       'Cognitive Science with a Specialization in Neuroscience ',\n",
       "       'Economics', 'computer engineering ',\n",
       "       'Cognitive Science with Specialization in Machine Learning and Neural Computation',\n",
       "       'Computer Engineering ', 'Economics ',\n",
       "       'Cognitive Science (Design & Interaction)',\n",
       "       'Cognitive Science Specialization in Design and Interaction',\n",
       "       'Cognitive Science w/ Focus on Human Computer Interaction', 'Math',\n",
       "       'Math-Computer Science',\n",
       "       'Cognitive Science with an emphasis in machine learning and neural computation',\n",
       "       'Math-Cs', 'Cogs Sci design specilization',\n",
       "       'Cognitive Science / HCI', 'Applied Mathematics', 'Applied math',\n",
       "       'Cognitive Science (Specialization in Design & Interaction)',\n",
       "       'MathCS', 'Chemical Engineering', 'Cogsci HCI',\n",
       "       'Cognitive Science-Design', 'cognitive science - hci',\n",
       "       'Computer science',\n",
       "       'Cognitive Science- Machine Learning & Neural Computation ',\n",
       "       'Bioinformatics', 'CogSci', 'Cognitive Science HCI',\n",
       "       'Cognitive Science in HCI', 'Cogs sci', 'Cogs machine learning',\n",
       "       'cogs hci', 'Bioinformatics ', 'Psychology',\n",
       "       'Math & Computer Science', 'Cog Sci HCI', 'MATH-CS',\n",
       "       'CogSci w/ Spec in HCI', 'Cogs Spec ML and NC',\n",
       "       'Probability and Statistics', 'Cognitive Neuroscience',\n",
       "       'Computer Science Engineer', 'Cogsci/HCI', 'CS',\n",
       "       'Physiology and neuroscience', 'Computer engineering ',\n",
       "       'Cognitive Science - HCI', 'Management Science',\n",
       "       'Cognit ive Science', 'Bioengineering ', 'ICAM & COGS',\n",
       "       'Cognitive Science with a Specialization in Human Cognition',\n",
       "       'cog sci', 'Cogs Sci HCI', 'Mathematics Computer Science ',\n",
       "       'Psychology and Cognitive Science ', 'Computer Engineer',\n",
       "       'Biochemistry and Cell Biology', 'Cognitive Science  ',\n",
       "       'Cognitive Science w/ HCI ', 'Cog Sci ',\n",
       "       'Cognitive science spec HCI', 'Cog sci',\n",
       "       'Cognitive Science (Machine Learning and Neural Computation)',\n",
       "       'Cognitive science neuroscience', 'CogSci specialization ML',\n",
       "       'Psychology Cognitive Science', 'Probability and statistics',\n",
       "       'Mathematics - Computer Science',\n",
       "       'Interdisciplinary Computing & the Arts',\n",
       "       'Cognitive Science - Neuroscience', 'Management Science ',\n",
       "       'Cognitive Science with a Specialization in Design and Interaction',\n",
       "       'MathCs', 'Cogs with specialization in HCI',\n",
       "       'Cognitive Science (with specialization in computation)', 'Cogs',\n",
       "       'COGS（ML）', 'Cognitive Science, Human-Computer Interaction',\n",
       "       'Cognitive Science specializing in Machine Learning and Computer Science double major',\n",
       "       'Cognitive Science - Specialization in Neuroscience.',\n",
       "       'Cognitive science machine learning and neural computation',\n",
       "       'Cognitive Science (Spec. Design and Interaction)',\n",
       "       'Machine Learning', 'Cognitive and Behavioral Neuroscience',\n",
       "       'Cog Sci, B.S and Poli Sci, B.A.', 'Human Computer Interaction',\n",
       "       'Electrical engineering', 'Linguistics',\n",
       "       'MathCS & CogsSci ML Double Major', 'bioinformatics',\n",
       "       'Cognitive science HCI',\n",
       "       'Cognitive Science- Human Computer Interaction',\n",
       "       'Cognitive Science - Machine Learning and Neural Computation',\n",
       "       'Cognitive science- design and interaction ',\n",
       "       'Cognitive Science- Neuroscience',\n",
       "       'Cognitive Science: Machine Learning & Neural Computation',\n",
       "       'Cognitive science specialized in machine learning and neural computetion',\n",
       "       'Cognitive Science with a Specialization in Machine Learning & Neural Computation ',\n",
       "       'Computer engineering', 'Neuroscience',\n",
       "       'General Linguistics and Cognitive Science (with Spec. in Clinical Aspects)',\n",
       "       'Cog Sci w/ specialization in Neuroscience', 'cs',\n",
       "       'COGS spc Machine Learning', 'COGS HCI ', 'Electrical engineer',\n",
       "       'Cognitive Science with specialization in Neuroscience ',\n",
       "       'Cognitive Science specializing in HCI',\n",
       "       'Cognitive Science: Neuroscience', 'Under-water Basket Weaving',\n",
       "       'computer science ',\n",
       "       'Cognitive Science specializing in Neuroscience ',\n",
       "       'CogSci Machine Learning', 'Bioengineering'], dtype=object)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all different values given for majors. It's a lot!\n",
    "df[\"major\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d52dff576b4b03cc21030d6a719d376",
     "grade": false,
     "grade_id": "cell-9385b62fe387df90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# We'll write a function performing some simple substring checking in order to group many responses together\n",
    "def standardize_major(string):\n",
    "    \n",
    "    string = string.lower()\n",
    "    string = string.strip()\n",
    "    \n",
    "    if \"cog\" in string:\n",
    "        output = \"COGSCI\"\n",
    "    elif \"computer\" in string:\n",
    "        output = \"COMPSCI\"\n",
    "    elif \"cs\" in string:\n",
    "        output = \"COMPSCI\"\n",
    "    elif \"math\" in string:\n",
    "        output = \"MATH\"\n",
    "    elif \"electrical\" in string:\n",
    "        output = \"ECE\"\n",
    "    elif \"bio\" in string:\n",
    "        output = \"BIO\"\n",
    "    elif \"chem\" in string:\n",
    "        output = \"CHEM\"\n",
    "    # Otherwise, if uncaught - keep as is\n",
    "    else:\n",
    "        output = string\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0644656f6748df3f118b9256540d710e",
     "grade": false,
     "grade_id": "cell-09d04f8d107994ce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Applying the transformation\n",
    "df[\"major\"] = df[\"major\"].apply(standardize_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d4c0a33b288ca371ac83a88b3801f96a",
     "grade": false,
     "grade_id": "cell-ebea1ef0aedc6e5e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COGSCI', 'COMPSCI', 'international studies', 'CHEM', 'ECE', 'MATH',\n",
       "       'data science', 'political science', 'BIO', 'psychology',\n",
       "       'physiology and neuroscience', 'management science',\n",
       "       'interdisciplinary computing & the arts', 'machine learning',\n",
       "       'neuroscience', 'under-water basket weaving'], dtype=object)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the results of the previous transformation. \n",
    "#   It looks a lot better, though it's not perfect, but we'll run with this\n",
    "df[\"major\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "450ce2c0f3f88dd2a43479185d6740d9",
     "grade": false,
     "grade_id": "cell-e81c26b20ffb78a5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Next let's check the 'gender' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male                 229\n",
       "Female                95\n",
       "female                26\n",
       "male                  18\n",
       "F                     10\n",
       "Male                   6\n",
       "Female                 6\n",
       "M                      6\n",
       "men                    1\n",
       "Famale                 1\n",
       "MALE                   1\n",
       "Rainbow                1\n",
       "Apache Helicopter      1\n",
       "Transgender            1\n",
       "Nonbinary              1\n",
       "Woman                  1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different responses received for gender, including how many of each response we have\n",
    "df[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2cf2567e70f49ff57e290c40fd244d4b",
     "grade": false,
     "grade_id": "cell-2720852762f49edd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to standardize the gender responses\n",
    "#  Note: for the purposes of the following analyses, we will keep self-reported gender for categories\n",
    "#    in which we have a sizable number of responses, in this case, those which correspond to 'female' and 'male'\n",
    "def standardize_gender(gender):\n",
    "    \n",
    "    gender = gender.lower()\n",
    "    gender = gender.strip()\n",
    "    \n",
    "    if gender in ['female', 'f', 'woman', 'women']:\n",
    "        output = 'female'\n",
    "    elif gender in ['male', 'm', 'man', 'men']:\n",
    "        output = 'male'\n",
    "    else: \n",
    "        output = np.nan\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "febadadd079549d3ad1fc605b8ef379e",
     "grade": false,
     "grade_id": "cell-291cf93820c28b6d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Apply the transformation, and drop any rows with missing gender information\n",
    "df[\"gender\"] = df[\"gender\"].apply(standardize_gender)\n",
    "df.dropna(subset=['gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eb838814a93bc151419cd45d1ab54026",
     "grade": false,
     "grade_id": "cell-17fff0622ea53c05",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female'], dtype=object)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "df[\"gender\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cbfaa8f970576c5b45ba74382cdc30e",
     "grade": false,
     "grade_id": "cell-6875237cc18599d2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now you will write some code to standardize some of the other data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e028c8d9e7493c066428aa057d725353",
     "grade": false,
     "grade_id": "cell-67b62cbc121b186a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1d) Find, programatically, the number of unique responses to in the 'year' column.\n",
    "# Save the result in a variable named 'num_unique_responses'. \n",
    "# Hint: you can answer this question using the 'unique' method, used above. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "num_unique_responses = df['year'].nunique()\n",
    "#num_unique_responses\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98948a6c0eba43b017a09696ff711e34",
     "grade": true,
     "grade_id": "cell-5f6082fc06a61a10",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert num_unique_responses\n",
    "assert isinstance(num_unique_responses, int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16d4f41f832456cbb5d2969cfc30a4a2",
     "grade": false,
     "grade_id": "cell-d0d60f556b961d79",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4', '3', 'Third', '2', '3rd', '3rd year', '5th', 'Second',\n",
       "       '4th Year', '5', 'Senior', 'Junior', '2nd', '1', 'senior', 'third',\n",
       "       'first year', '4th', 'Junior ', 'Freshman', 'Sophomore', '4th year',\n",
       "       '6', 'second year', 'Third Year', '2nd year', 'First',\n",
       "       '5th (2nd year transfer)', '2018', 'last year', 'UCSD',\n",
       "       'Fifth Year', '2021', 'Fifth year', '3rd Year', '3rd year ',\n",
       "       'Second year', 'fourth year', 'First year', 'Sophmore',\n",
       "       'Second Year', 'Junior year', '2020', 'Fifth ', 'Sophomore ',\n",
       "       '2nd year ', '4th year ', '2nd Year', '4+', 'second', 'Fourth',\n",
       "       'Senior Year', '2nd (Sophomore)', 'Senior ', ' 3rd Year',\n",
       "       'Fourth Year', 'Junior standing', 'Fourth year', 'Fifth',\n",
       "       'Third year', 'Sineor '], dtype=object)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out all the different answers in 'year'\n",
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b573833a7240fad96b2c6cbd6c66ffb",
     "grade": false,
     "grade_id": "cell-3c5e3e0128fbe90b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The line of code above shows us the different values we got, to the question 'What year (in school) are you?'.\n",
    "\n",
    "As you can tell, it is a <b>mess</b>!. For example, if you are a junior student, then you might have answered: 3, three, third, 3rd year, junior, junior year, Junior, etc. \n",
    "\n",
    "That is an issue. We want to be able to analyze this data and, in order to do this successfully, we need to all answers with the same meaning to be written in the same way. Therefore, we're gonna have to transform answers such as '3, third, 3rd, junior, etc' into a single possible value. We'll do this for all values that mean the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "545906fe22276a6cd34616277cec8c57",
     "grade": false,
     "grade_id": "cell-2b7366b65afc6bcc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In the rest of Part 1, we will work on writing code, organized into functions that will allow us to transform similar respones into the same value. We will call this process: standardizing the data. \n",
    "\n",
    "The cell below provides an example for the kind of code you will need to write to answer this question. This example is separate from our actual data, and is a potential function we might use to standardize messy data - in this case, hypothetical data to the question 'What is your favourite major python version?'. \n",
    "\n",
    "Note some things used in this example that you need to use to standardize data:\n",
    "- string methods, such as 'lower' and 'strip' to transform strings\n",
    "- the 'replace' string method, to replace a set of characters with something else\n",
    "- if/else statements that check what's in our string (number, letters, etc)\n",
    "- type casting, for example using 'int()' to turn a variable into an integer\n",
    "- using 'np.nan' (which stands for 'not a number') to denote missing or unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ffd45db3371083149d9eaf9b66d11cd8",
     "grade": false,
     "grade_id": "cell-f17c3740350c93ec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT \t\t-\t OUTPUT\n",
      "version 3  \t-\t 3\n",
      "42         \t-\t nan\n",
      "2          \t-\t 2\n",
      "python 3   \t-\t 3\n",
      "nonsense-lolz \t-\t nan\n"
     ]
    }
   ],
   "source": [
    "def example_standardize_function(str_in):\n",
    "    \"\"\"Standardize data to the question 'what is your favourite major python version?'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    str_in : string\n",
    "        A provided answer.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int_out : int or np.nan\n",
    "        A standardized integer response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make the input all lowercase\n",
    "    str_in = str_in.lower()\n",
    "    \n",
    "    # Drop all whitespace\n",
    "    str_in = str_in.strip()\n",
    "    \n",
    "    # Replace things (and then strip again afterwords)\n",
    "    #  Note that the 'replace' replaces the first argument, with the second\n",
    "    #   The first argument does not need to be present in the string,\n",
    "    #    if it's not there 'replace' does nothing (but does not error), so the code moves on.\n",
    "    str_in = str_in.replace('version', '')\n",
    "    str_in = str_in.replace('python', '')\n",
    "    str_in = str_in.strip()\n",
    "    \n",
    "    # Cast to integer, if what's left seems appropriate\n",
    "    if str_in.isnumeric() and len(str_in) == 1:\n",
    "        out = int(str_in)\n",
    "    # Otherwise, consider input was probably ill-formed, return nan\n",
    "    else: \n",
    "        out = np.nan\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Check how this function help standardize data:\n",
    "#  Example possible answers to the question 'What is your favourite major version of Python':\n",
    "print('INPUT', '\\t\\t-\\t', 'OUTPUT')\n",
    "for inp in ['version 3', '42', '2', 'python 3', 'nonsense-lolz']:\n",
    "    print('{:10s} \\t-\\t {:1.0f}'.format(inp, example_standardize_function(inp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "88aeecbe5556335713948e0f4480d9e4",
     "grade": false,
     "grade_id": "cell-0d5ebacd71733a00",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1e) Write a function named 'standardize_year' that takes in as input a string and returns an integer.\n",
    "# The function will do the following (in the order specified):\n",
    "#  Note that for these detailed instructions, each line corresponds to one line of code you need to write.\n",
    "#\n",
    "# - 1) convert all characters of the string into lowercase\n",
    "# - 2) strip the string of all leading and trailing whitespace\n",
    "#\n",
    "# - 3) replace any occurences of 'first' with '1'\n",
    "# - 4) replace any occurences of 'second' with '2'\n",
    "# - 5) replace any occurences of 'third' with '3'\n",
    "# - 6) replace any occurences of 'fourth' with '4'\n",
    "# - 7) replace any occurences of 'fifth' with '5'\n",
    "# - 8) replace any occurences of 'sixth' with '6'\n",
    "#\n",
    "# - 9) replace any occurences of 'freshman' with '1'\n",
    "# - 10) replace any occurences of 'sophomore' with '2'\n",
    "# - 11) replace any occurences of 'junior' with '3'\n",
    "# - 12) replace any occurences of 'senior' with 4'\n",
    "#\n",
    "# - 13) replace any occurences of 'year' with '' (remove it from the string)\n",
    "# - 14) replace any occurences of 'th' with '' (remove it from the string)\n",
    "# - 15) replace any occurences of 'rd' with '' (remove it from the string)\n",
    "# - 16) replace any occurences of 'nd' with '' (remove it from the string)\n",
    "#\n",
    "# - 17) strip the string of all leading and trailing whitespace (again)\n",
    "# - 18) If the resulting string is a number and it is less than 10:\n",
    "#            then cast it into an integer and return that value\n",
    "# - 19) Else:\n",
    "#            return np.nan to symbolize that the student's response was not a valid entry\n",
    "#\n",
    "# HINTS: you will need to use the functions 'lower()', 'strip()', isnumeric() and 'replace()'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def standardize_year(string):\n",
    "    \n",
    "    string = string.lower()\n",
    "    string = string.strip()\n",
    "    \n",
    "    if \"first\" in string:\n",
    "        #output = \"1\"\n",
    "        return 1\n",
    "    elif \"second\" in string:\n",
    "        #output = \"2\"\n",
    "        return 2\n",
    "    elif \"third\" in string:\n",
    "        #output = \"3\"\n",
    "        return 3\n",
    "    elif \"fourth\" in string:\n",
    "        #output = \"4\"\n",
    "        return 4\n",
    "    elif \"fifth\" in string:\n",
    "        #output = \"5\"\n",
    "        return 5\n",
    "    elif \"sixth\" in string:\n",
    "        #output = \"6\"\n",
    "        return 6\n",
    "    elif \"freshman\" in string:\n",
    "        #output = \"1\"\n",
    "        return 1\n",
    "    elif \"sophomore\" in string:\n",
    "        #output = \"2\"\n",
    "        return 2\n",
    "    elif \"junior\" in string:\n",
    "        #output = \"3\"\n",
    "        return 3\n",
    "    elif \"senior\" in string:\n",
    "        #output = \"4\"\n",
    "        return 4\n",
    "        \n",
    "\n",
    "    string = string.replace(\"year\", \"\")\n",
    "    string = string.replace(\"th\", \"\")\n",
    "    string = string.replace(\"rd\", \"\")\n",
    "    string = string.replace(\"nd\", \"\")    \n",
    "    #return string\n",
    "    string = string.strip()\n",
    "    if string.isnumeric() and int(string) < 10:\n",
    "        return int(string)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    #return output\n",
    "    \n",
    "    \n",
    "\n",
    "#temp = standardize_year('randomText')\n",
    "#print(temp)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f5a61f7a347cfeb00b1012786a6feeda",
     "grade": true,
     "grade_id": "cell-ba092cbd3aa73da8",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert standardize_year('2nd') == 2\n",
    "assert standardize_year('sophomore') == 2\n",
    "assert standardize_year('3rd year') == 3\n",
    "assert standardize_year('5th') == 5\n",
    "assert standardize_year('7    ') == 7\n",
    "assert standardize_year('randomText') is np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "826bbfbb04f5ee17edf7a6fc35354dc1",
     "grade": false,
     "grade_id": "cell-9e2b64ce81ef09c3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1f) Use 'standardize_year' to transform the data in column 'What year (in school) are you?'.\n",
    "# Hint: use the apply function AND remember to save your output inside the dataframe\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df['year'] = df['year'].apply(standardize_year)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5788f3815d6ed1ada22c4238b932910",
     "grade": true,
     "grade_id": "cell-e4c266be688ef4d8",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df[\"year\"].unique()) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a389f4e23bf7622e21618764cccf95c8",
     "grade": false,
     "grade_id": "cell-5a3e9946608829bc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Assuming that all is correct up to this point, the line below should show all values now found in df. \n",
    "\n",
    "It should look a lot better. With this data, we can now make insightful analyses.\n",
    "\n",
    "You should see an array with elements 1,2,3,4,5,6 and nan (not necessarily in that order).\n",
    "\n",
    "Note that if you check the data type of this column, you'll see that pandas converts these numbers to 'float', even though the applied function returns 'int', because 'np.nan' is considered a float. This is fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9ce7cce6559ea59327891eb51c467f08",
     "grade": false,
     "grade_id": "cell-898e3b677a0502e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   3.,   2.,   5.,   1.,   6.,  nan])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a8cab23272a975ecdff26c44de0fe880",
     "grade": false,
     "grade_id": "cell-4f6c1c2d7afe02e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's do it again. Let's take a look at the responses in the 'weight' column, and then standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, ensure that all types are consistent, use strings\n",
    "df[\"weight\"] = df[\"weight\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b578c243a17c6e54f451b6847b096408",
     "grade": false,
     "grade_id": "cell-1da977c3f5a68607",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['147', '150', '74kg', '133', '160', '106 lb', '155', '170 pounds',\n",
       "       '170', '135', '115', '110', '167 lbs', '60kg', '136', '140', '120',\n",
       "       '78kg', '128 lbs', '220', '145lb', '180', '95', '160lbs', '130',\n",
       "       '177g', '125 pounds', '125', '210', '69kg', '165', '160 lbs', '123',\n",
       "       '135lbs', '112 pounds', '190', '145lbs', '150 lbs', 'nan', '173lbs',\n",
       "       '73kg', '133 lb', '107 pounds', '200', '240', '47kg', '175',\n",
       "       '120 lbs', '164', '110 lbs', '128lbs', '155 lb', '185', '167',\n",
       "       '84 kg', '113', '235', '128lb', '119 lbs', '110 lb', '72kg', '122',\n",
       "       '140 lbs', '70 kg', '155 pounds ', '128', '125 lb', '108', '15',\n",
       "       '215', '48kg', '52kg', '145', '185lbs. ', '230lb', '125 lbs',\n",
       "       '140 lb', '168lb', '100', '130 pounds', '124', '84kg', '119',\n",
       "       \"I don't know dude but heavy probably\", '103', '140lbs', '170lbs',\n",
       "       '155 lbs', '50kg', '190 lbs', '52 kg', '168lbs', '189', '168',\n",
       "       '76KG', '77kg', '181', '146', '156', '140 pounds', '128 lb', '46kg',\n",
       "       '140 lb ', '120 lb', '146lb', '169lb', '250', '130lb', '146 Pounds',\n",
       "       '58 kg', '173lb', '70kg', '56 kg', '190lb', 'Secret', '66 kg',\n",
       "       '134', '125lb', '145 lbs', '102 lbs', '67kg', '51kg', '105', '320',\n",
       "       '142', '130 lbs.', '145 pounds', '119lb', '280', '95kg', '175 lbs',\n",
       "       '58lbs', '134 pounds', '129', '85kg', '152 lbs', '138 pounds',\n",
       "       '112', '141', '100lbs', '102 kbs', '98 lb', '91 kg', '107 lb',\n",
       "       '150lb', '145 lbs ', '205', '98lbs', '145 lb.', '112 lbs', '106',\n",
       "       '124pounds', '110 pounds', '82kg', \"6'1\", '100 lbs', '45kg', '154',\n",
       "       '122 pounds', '150 lb', '155lb', '179lb', '130 lbs', '158', '116',\n",
       "       '107 lbs', '105 lbs', '91 lbs', '168 lb', '140lb', '76kg', '75',\n",
       "       '145 lb', '85 kg', '114', '105 pounds', '115 lbs', '85', '102',\n",
       "       '85 lbs', '63kg', '160 pounds', '185 lbs'], dtype=object)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the different answers we received\n",
    "df[\"weight\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eb82e67975bdce2f3318c7a777d7a143",
     "grade": false,
     "grade_id": "cell-95fed6ce419a8d85",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1g) Write a function named 'standardize_weight' that takes in as input a string and returns an integer.\n",
    "# The function will do the following (in the order specified):\n",
    "#\n",
    "# - 1) convert all characters of the string into lowercase\n",
    "# - 2) strip the string of all leading and trailing whitespace\n",
    "#\n",
    "# - 3) replace any occurences of 'lbs' with '' (remove it from the string)\n",
    "# - 4) replace any occurences of 'lb' with '' (remove it from the string)\n",
    "# - 5) replace any occurences of 'pounds' with '' (remove it from the string)\n",
    "#\n",
    "# - 6) If the string contains the substring 'kg', then:\n",
    "# ------ 6.1) replace 'kg' with ''\n",
    "# ------ 6.2) cast the string into an integer type using the function 'int()'\n",
    "# ------ 6.3) multiply the resulting integer by 2 (an approximate conversion of kilograms to pounds)\n",
    "# ------ 6.4) cast the resulting number back into a string with the function 'str()'\n",
    "#\n",
    "# - 7) Strip the string of its whitespaces (again)\n",
    "# - 8) If the resulting string is numeric:\n",
    "#           cast it into an integer and return the resulting value\n",
    "# - 9) Else:\n",
    "#.          return np.nan\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def standardize_weight(string):\n",
    "    \n",
    "    strng = string.lower()\n",
    "    strng = strng.strip()\n",
    "    \n",
    "    strng = strng.replace(\"lbs\", \"\")\n",
    "    strng = strng.replace(\"lb\", \"\")\n",
    "    strng = strng.replace(\"pounds\", \"\")\n",
    "    \n",
    "    if \"kg\" in string:\n",
    "        strng = strng.replace(\"kg\", \"\")\n",
    "        strng = int(strng)\n",
    "        strng = strng * 2\n",
    "        strng = str(strng)\n",
    "        \n",
    "    strng = strng.strip()\n",
    "    if strng.isnumeric():\n",
    "        return int(strng)\n",
    "    else:\n",
    "        return np.nan\n",
    "    return \n",
    "    \n",
    "#weight_test = standardize_weight('101 kg')\n",
    "#weight_test\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "713b14e2f7a300ab547d58111e21a82f",
     "grade": true,
     "grade_id": "cell-50d719bde09d79ca",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert standardize_weight('34 lbs') == 34\n",
    "assert standardize_weight('101 kg') == 202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a1014b22166f76587dd5f0d25416fdeb",
     "grade": false,
     "grade_id": "cell-e359512e3c8a1667",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1h) Use 'standardize_weight' to transform the data in the 'weight' column.\n",
    "# Hint: use the apply function AND remember to save your output inside the dataframe\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df['weight'] = df['weight'].apply(standardize_weight)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9626e984524f4d3e0fbaca22b60502cd",
     "grade": true,
     "grade_id": "cell-aec6ff6de9a88081",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df[\"weight\"].unique().shape == (83,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "64936a6e96f8a6fb80fd7ad5879b4b38",
     "grade": false,
     "grade_id": "cell-0b4cc15bc5d0d5fc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, let's see the result of our hard work . The code below should output all numbers (or nan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "443f6f46a5453a69c0eae0f2ca65f7dd",
     "grade": false,
     "grade_id": "cell-7597a3a13c682b42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 147.,  150.,  148.,  133.,  160.,  106.,  155.,  170.,  135.,\n",
       "        115.,  110.,  167.,  120.,  136.,  140.,  156.,  128.,  220.,\n",
       "        145.,  180.,   95.,  130.,   nan,  125.,  210.,  138.,  165.,\n",
       "        123.,  112.,  190.,  173.,  146.,  107.,  200.,  240.,   94.,\n",
       "        175.,  164.,  185.,  168.,  113.,  235.,  119.,  144.,  122.,\n",
       "        108.,   15.,  215.,   96.,  104.,  230.,  100.,  124.,  103.,\n",
       "        189.,  154.,  181.,   92.,  169.,  250.,  116.,  132.,  134.,\n",
       "        102.,  105.,  320.,  142.,  280.,   58.,  129.,  152.,  141.,\n",
       "         98.,  182.,  205.,   90.,  179.,  158.,   91.,   75.,  114.,\n",
       "         85.,  126.])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"weight\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42688d8836aa49e8b8eba0e62d041699",
     "grade": false,
     "grade_id": "cell-a4aeb2f0805cd10f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "So far, you've gotten a taste of what it is like to deal with messy data. It's not easy, as you can tell. \n",
    "\n",
    "The last variable we need to standardize for the purposes of our analysis is 'height'. We will standardize that one for you.\n",
    "\n",
    "Do read the code below and try to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a51026a175b4c0719ab553783c698d63",
     "grade": false,
     "grade_id": "cell-ea232e3affe16d6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5\\'8\"', \"5'8\", '178cm', '5’8', '5\\'11\"', \"5'9\", '5 ft, 3 in',\n",
       "       \"5'10\", '180 cm', '5\\'3\"', '5\\'9\"', '5\\'2\"', '5ft 5inches', '158cm',\n",
       "       '5\\'7\"', '5 feet 8 inches', \"5'7''\", \"5' 8'' \", '184cm', '5\\' 7\"',\n",
       "       '6’2”', \"6'1''\", \"4'11\", '5\\'10\"', '173', '177cm', '5\\'6\"', \"5'4\",\n",
       "       '5’5', \"5'5\", \"6'2\", '171cm', \"5' 5''\", \"5'2\", \"5'7\", '5\\' 8\"',\n",
       "       \"5'3\", '5 feet 9 inches', '6’0', '5’3', \"5'11\", '64 in', \"5' 7''\",\n",
       "       '5ft 2in', '5’3”', '66', '173cm', '5’8”', '5 feet 2 in', '5 7',\n",
       "       '6’', '5.4', '6 feet', '5’0”', '1.6m', '5 ft 2 in', '5\\'1\"', '5’5”',\n",
       "       \"5' 8''\", '6\\'2\"', '6\\'4\"', '5\\'8.5\"', '178 cm', '5\\'5\"', \"6'1\",\n",
       "       '5”7’', '174cm', '71', \"5' 1\", '6 ft', '5” 4’', '177 cm',\n",
       "       '69 inches ', \"5'4''\", '5\\' 4\"', '5 foot 11', \"5''2'\",\n",
       "       '6 feet 0 inches', '67', '167cm', '6\\'1\"', \"5'11''\", '168cm', '5\"8',\n",
       "       '5\\' 10\"', '6ft', '163 cm', '5 Feet 6 inches', '6.1', \"5' 3''\",\n",
       "       '5 foot 7', '5 ft 3', '5 7\"', '172 cm', '6-5', '5’ 6’’', '6’0”',\n",
       "       \"5'0\", '6 foot', '6’ 1”', '5-10', \"5'\", '5 ft 8 in',\n",
       "       '5 foot 11 inches', '6', '5’6”', '1.7 m', '178', '5\\' 6\"', '5 11',\n",
       "       \"5'1\", '5’4', '5 ft. 9 in', '170 cm ', '6 ft 1 in', '5’9', '5’ 10”',\n",
       "       \"6'\", '190cm', \"5'8 feet\", '6’q', '5 ft 7 in', '5 foot 10',\n",
       "       '5 foot 8 inches', '5’9”', '161cm', '5 ft', '5’ 5”', '5’8’’',\n",
       "       '6\\'3\"', '5’10', '5’6', \"5' 10''\", '5 Feet 11 Inches', '5 foot 6',\n",
       "       \"6'3''\", '162 cm', '65in', '5’8.5”', \"5' 1''\", '185 cm',\n",
       "       '6 feet 1 in', '176cm', 'Secret', '5’11', '170 cm', '5 feet 4 in',\n",
       "       \"5'3''\", '175cm', '5ft 7in', '67in', '5’1', '179cm', '160cm',\n",
       "       '5\\'0\"', \"5'6\", '5 ft 10 in', '5\\' 9\"', '6 feet 0 inch', '5”6’',\n",
       "       '4\\'11\"', '65 inches', '172cm', '189', \"165 cm/5'4'' feet\", '6\\'0\"',\n",
       "       '5ft 6in', '5\\' 6.5\"', '6\\' 1.5\"', '5’7”', '5’2”', '5 ft 8in',\n",
       "       '5 feet and 9 1/2 inches', '5.8', '6’4”', '5\\'4\"', '5”4',\n",
       "       '5 ft 2 in.', '5’ 2”', '72 inches', '5 ft 3 inches',\n",
       "       '5 feet 6 inches', '6\\' 1\"', '5”6', \"6'0\", '186cm', '167', '5’10”',\n",
       "       '5 8', '6`1``', '1.6meter', '5 foot 3 inches', '5.9', '70',\n",
       "       '5 ft 7', '5’7’’', '5’ 2', '5 foot ', '4\\'20\"', '4’11', \"5'0''\",\n",
       "       '5foot 7inch', '5’7', '5\\' 11\"', '5 10', '4 ft 11 inches', '176',\n",
       "       '5', '5\\' 02\"', '5’1”', '4’ 11”', '5’ 3.75”', '5 ft 4 in', '4’ 10”',\n",
       "       '5 5', '68in', '6’1”'], dtype=object)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll look at the possible values for height\n",
    "df[\"height\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75e360a6c42e08ec8df4743bfe4dbb66",
     "grade": false,
     "grade_id": "cell-c275572c89e5fca6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# It seems like we'll have to handle different measurement systems. Ugh, ok...\n",
    "# Let's write a function that converts all those values to inches\n",
    "\n",
    "def standardize_height(string):\n",
    "    \n",
    "    orig = string\n",
    "    output = None\n",
    "    \n",
    "    # Basic string pre-processing\n",
    "    string = string.lower()\n",
    "    string = string.strip()\n",
    "    \n",
    "    string = string.replace(\"foot\", \"ft\")\n",
    "    string = string.replace(\"feet\", \"ft\")\n",
    "    string = string.replace(\"inches\", \"in\")\n",
    "    string = string.replace(\"inch\", \"in\")\n",
    "    string = string.replace(\"meters\", \"m\")\n",
    "    string = string.replace(\"meter\", \"m\")\n",
    "    string = string.replace(\"centimeters\", \"cm\")\n",
    "    string = string.replace(\"centimeter\", \"cm\")\n",
    "    string = string.replace(\",\", \"\")\n",
    "    string = string.strip()\n",
    "    \n",
    "    # CASE 1: string is written in the format FEET <DIVIDER> INCHES\n",
    "    dividers = [\"'\", \"ft\", \"’\", '”', '\"','`', \"-\", \"''\"]\n",
    "    for divider in dividers:\n",
    "        \n",
    "        # Split it into its elements\n",
    "        elements = string.split(divider)\n",
    "\n",
    "        # If the divider creates two elements\n",
    "        if (len(elements) >= 2) and ((len(string) -1) != string.find(divider)):\n",
    "            feet = elements[0]\n",
    "            inch = elements[1] if elements[1] is not '' else '0'\n",
    "            \n",
    "            # Cleaning extranious symbols\n",
    "            for symbol in dividers:\n",
    "                feet = feet.replace(symbol, \"\")\n",
    "                inch = inch.replace(symbol, \"\")\n",
    "                inch = inch.replace(\"in\",\"\")\n",
    "            \n",
    "            # Removing whitespace\n",
    "            feet = feet.strip()\n",
    "            inch = inch.strip()\n",
    "            \n",
    "            # By this point, we expect 'feet' and 'inch' to be numeric\n",
    "            # If not...we ignore this case\n",
    "            if feet.replace('.', '').isnumeric() and inch.replace('.', '').isnumeric():\n",
    "                \n",
    "                # Converting feet to inches and adding it to the curent inches\n",
    "                output = (float(feet) * 12) + float(inch)\n",
    "                break\n",
    "            \n",
    "    # CASE 2: string is written in the format FEET ft INCHES in \n",
    "    if (\"ft\" in string) and (\"in\" in string):\n",
    "        \n",
    "        # Split it into its elements\n",
    "        elements = string.split(\"ft\")\n",
    "        feet = elements[0]\n",
    "        inch = elements[1]\n",
    "        \n",
    "        # Removing extroneous symbols and stripping whitespace\n",
    "        inch = inch.replace(\"inch\", \"\")\n",
    "        inch = inch.replace(\"in\", \"\")\n",
    "        feet = feet.strip()\n",
    "        inch = inch.strip()\n",
    "        \n",
    "        # By this point, we expect 'feet' and 'inch' to be numeric\n",
    "        # If not...we ignore this case\n",
    "        if feet.replace('.', '').isnumeric() and inch.replace('.', '').isnumeric():\n",
    "                \n",
    "            # Converting feet to inches and adding it to the curent inches\n",
    "            output = (float(feet) * 12) + float(inch)\n",
    "        \n",
    "    # CASE 3: answer was given ONLY in cm\n",
    "    #  Convert to inches: approximately 0.39 inches in a meter\n",
    "    elif \"cm\" in string:\n",
    "        centimeters = string.replace(\"cm\", \"\")\n",
    "        centimeters = centimeters.strip()\n",
    "        \n",
    "        if centimeters.replace('.', '').isnumeric():\n",
    "            output = float(centimeters) * 0.39\n",
    "        \n",
    "    # CASE 4: answer was given ONLY in meters\n",
    "    #  Convert to inches: approximately 39 inches in a meter\n",
    "    elif \"m\" in string:\n",
    "        \n",
    "        meters = string.replace(\"m\", \"\")\n",
    "        meters = meters.strip()\n",
    "        \n",
    "        if meters.replace('.', '').isnumeric():\n",
    "            output = float(meters)*39\n",
    "        \n",
    "    # CASE 5: answer was given ONLY in feet\n",
    "    elif \"ft\" in string:\n",
    "\n",
    "        feet = string.replace(\"ft\", \"\")\n",
    "        feet = feet.strip()\n",
    "        \n",
    "        if feet.replace('.', '').isnumeric():\n",
    "            output = float(feet)*12\n",
    "    \n",
    "    # CASE 6: answer was given ONLY in inches\n",
    "    elif \"in\" in string:\n",
    "        inches = string.replace(\"in\", \"\")\n",
    "        inches = inches.strip()\n",
    "        \n",
    "        if inches.replace('.', '').isnumeric():\n",
    "            output = float(inches)\n",
    "        \n",
    "    # CASE 7: answer not covered by existing scenarios / was invalid. \n",
    "    #  Return NaN\n",
    "    if not output:\n",
    "        output = np.nan\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7373e53737f6061d25a913c8bd32a6e",
     "grade": false,
     "grade_id": "cell-fba0c212116f4fa0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Applying the transformation and dropping invalid rows\n",
    "df[\"height\"] = df[\"height\"].apply(standardize_height)\n",
    "df.dropna(subset=['height'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc3ff5a0fcc9059d835a5d17ebfb3615",
     "grade": false,
     "grade_id": "cell-57f6d2bac3cd54b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68.  ,  69.42,  71.  ,  69.  ,  63.  ,  70.  ,  70.2 ,  62.  ,\n",
       "        65.  ,  61.62,  67.  ,  71.76,  74.  ,  73.  ,  59.  ,  69.03,\n",
       "        66.  ,  64.  ,  66.69,  72.  ,  67.47,  60.  ,  62.4 ,  61.  ,\n",
       "        76.  ,  68.5 ,  67.86,  65.13,  65.52,  63.57,  67.08,  77.  ,\n",
       "        66.3 ,  74.1 ,  62.79,  75.  ,  63.18,  72.15,  68.64,  68.25,\n",
       "        69.81,  66.5 ,  73.5 ,  72.54,  63.75,  58.  ])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the height data, after applying our standardization\n",
    "df[\"height\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bde7ee1bc048c917394dd5d49e44d835",
     "grade": false,
     "grade_id": "cell-f89d49db32f46fe6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>major</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>born_in_CA</th>\n",
       "      <th>favorite_icecream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/9/2018 14:49:40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "      <td>68.00</td>\n",
       "      <td>147.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/9/2018 14:49:45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>68.00</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies and Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/9/2018 14:49:45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "      <td>69.42</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Matcha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/9/2018 14:49:45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COGSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>68.00</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies and Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2018 14:49:47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMPSCI</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>68.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cookies n' Cream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp  year    major  age gender  height  weight eye_color  \\\n",
       "0  1/9/2018 14:49:40   4.0   COGSCI   21   male   68.00   147.0     Brown   \n",
       "1  1/9/2018 14:49:45   3.0   COGSCI   20   male   68.00   150.0     Brown   \n",
       "2  1/9/2018 14:49:45   3.0  COMPSCI   21   male   69.42   148.0     Black   \n",
       "3  1/9/2018 14:49:45   2.0   COGSCI   20   male   68.00   133.0     Brown   \n",
       "4  1/9/2018 14:49:47   3.0  COMPSCI   20   male   68.00   160.0     Brown   \n",
       "\n",
       "  born_in_CA  favorite_icecream  \n",
       "0        Yes            Vanilla  \n",
       "1        Yes  Cookies and Cream  \n",
       "2        Yes             Matcha  \n",
       "3        Yes  Cookies and Cream  \n",
       "4        Yes   Cookies n' Cream  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring that the data types are correct - type cast age to int.\n",
    "df[\"age\"] = df[\"age\"].astype(np.int64)\n",
    "\n",
    "# Check out the data, after we've cleaned it!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a573935ae4ffb19b76f77e9988ed4b95",
     "grade": false,
     "grade_id": "cell-1c6f53e910ea33ba",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check that the dataframe has the right number of columns\n",
    "#  If this doesn't pass - check your code in the section above.\n",
    "assert len(df) == 367"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec3ec822434b84bd3c7dba440532d7d6",
     "grade": false,
     "grade_id": "part2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Exploratory Data Vizualization\n",
    "\n",
    "First, we need to do some exploratory data visualization, to get a feel for the data. \n",
    "\n",
    "For plotting questions, do not change or move the 'plt.gcf()' lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "336844f08518dbd0fd40691447cd1623",
     "grade": false,
     "grade_id": "2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2a) Plot the data, using scatter_matrix, from Pandas. Assign it to a variable called 'fig'.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dda209e2a124e2b124c7ffe2418cf3f0",
     "grade": true,
     "grade_id": "2a_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a1497f94569e78935882bea93c45582b",
     "grade": false,
     "grade_id": "2b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2b) Plot a bar chart showing the number of students in each majors. \n",
    "#  Hints: you can use 'value_counts' to get the counts for each major. \n",
    "#    You can then use the 'plot' method from pandas for plotting - you don't need matplotlib. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "f1 = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a047bb5826235f3045d06dc048ad6f8",
     "grade": true,
     "grade_id": "2b_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert f1.gca().has_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "22e1f73b6b0bfcf33b7dcbf0ed514d1a",
     "grade": false,
     "grade_id": "2c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2c) Plot a histogram of the height data for all students who wrote 'COGSCI' as their major.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "f2 = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "681d680c639d540a65b36cad3e3d76a3",
     "grade": true,
     "grade_id": "2c_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert f2.gca().has_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "45cc0ae885edb960380c38de668fff23",
     "grade": false,
     "grade_id": "2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2d) Plot a histogram of the height data for all students who wrote 'COMPSCI' as their major.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "f3 = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e3fdfa9bb5c8cfd753650beb5bf9f336",
     "grade": true,
     "grade_id": "2d_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert f3.gca().has_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4c95123e847ab5c0b71765d0b28f2354",
     "grade": false,
     "grade_id": "part3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Exploring The Data\n",
    "\n",
    "Beyond just plotting the data, we should check some other basic properties of the data. This serves both as a way to get a 'feel' for the data, and to look for any quirks or oddities about the data, that may indicate issues that need resolving. To do this, let's explore that data a bit (not limiting ourselves to only features that we plan to use - exploring the dataset as a whole can help us find any issues). \n",
    "\n",
    "Notes:\n",
    "- You answers should NOT be pandas objects (Series or DataFrames), extract answers so the variables are ints, floats or strings (as appropriate).\n",
    "- You must answer these questions programmatically: do not count / check and hard code particular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "54e674714945bb012baaccc98d184976",
     "grade": false,
     "grade_id": "3a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3a) How many different majors are in the dataset?\n",
    "#  Save this number to a variable 'n_majors'. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8eda66609f29df11974c224eef26cd92",
     "grade": true,
     "grade_id": "3a_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert n_majors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f4ca0bfab45f5a05cc6b6f815d093481",
     "grade": false,
     "grade_id": "3b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3b) What is the range (max value - min value) of ages in the dataset?\n",
    "#  Save this number to a variable 'r_age'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "14d660b6d9a58054f89853be46d36c29",
     "grade": true,
     "grade_id": "3b_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert r_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b2d0236211a0d78e64d354f039dafc3f",
     "grade": false,
     "grade_id": "3c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3c) What is the most popular ice cream flavour?\n",
    "#  Save the ice cream name to the variable 'f_ice', and the number of people who like it to a variable 'n_ice'.\n",
    "#  Hint: you can get these values using the 'value_counts' method.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf09e7a0c647ef6847c8f6e179b3f02f",
     "grade": true,
     "grade_id": "3c_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert n_ice\n",
    "assert f_ice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c0ac160b80c121ef905bac02f9356e55",
     "grade": false,
     "grade_id": "3d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3d) How many people have a unique favourite ice cream? (How many ice cream flavours are only 1 persons favourite?)\n",
    "#  Save this number to a variable 'u_ice'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19026d7e5e1df56a8bd90974fab34348",
     "grade": true,
     "grade_id": "3d_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert u_ice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fab6973ac47cf457ab80882b3d436410",
     "grade": false,
     "grade_id": "cell-2d665b435307d5d8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 4: Testing Distributions\n",
    "\n",
    "Soon, in the data analysis, we will want to run some statistical tests on our data. First, we should check the distributions!\n",
    "\n",
    "When using methods / statistical tests that make certain assumptions, it's always best to explicitly check if your data meet those assumptions (otherwise the results may be invalid). Let's test if our data are in fact normally distributed. \n",
    "\n",
    "See an example of how to test the disributions of data in the 'TestingDistributions' notebook in Tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da9d11910030325765de2c974f897b59",
     "grade": false,
     "grade_id": "cell-392680c490101a20",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# For convenience, and consistency, we're providing this code to pull out the required data\n",
    "h_co = df[df['major'] == 'COGSCI']['height'].values\n",
    "h_cs = df[df['major'] == 'COMPSCI']['height'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0ced212f876769115b34eacebefa64a8",
     "grade": false,
     "grade_id": "cell-da8e2581c20cc94b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 4a) For each of 'h_co', and 'h_cs', use the 'normaltest' function to test for normality of the distribution.\n",
    "#  'normaltest' returns two values, a test statistic and a p-value\n",
    "#    Save these values as 'st_co', 'p_co', 'st_cs', and 'p_cs' respectively.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acd00c360f2f07f5eab47b845adfd70b",
     "grade": true,
     "grade_id": "cell-4dd51f5136f5b627",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert st_co\n",
    "assert p_co\n",
    "assert st_cs\n",
    "assert p_cs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b436e250bb6644867b35dad737be293",
     "grade": false,
     "grade_id": "cell-0fd213731126131a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Have a look at the values returned. \n",
    "\n",
    "Based on these results, and using an alpha significance value of 0.01:\n",
    "\n",
    "Set boolean values (True, False) of whether each distribution can be considered to be normally distributed (set as True if the test supports it is normally distributed (or, more formally, we have not rejected the null hypothesis), and False if the test suggests the data is not normally distributed (we should reject the null hypothesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8f74c592a3cb43b0ebddaaed8394aa7",
     "grade": false,
     "grade_id": "cell-158f8c1d15bd1824",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 4b) Set boolean values, as specified above.\n",
    "#  For the 'h_co' data, set a boolean value to the var 'is_n_co'\n",
    "#  For the 'h_cs' data, set a boolean value to the var 'is_n_cs'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "923c9c11d179ce1c3a26976c4dfac442",
     "grade": true,
     "grade_id": "cell-8a1204d6fb264c05",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(is_n_co, bool)\n",
    "assert isinstance(is_n_cs, bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bf6edffcf16e2fe08aa27880838bdc4e",
     "grade": false,
     "grade_id": "cell-ce24c1eaa5caff05",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# CO data: plot the comparison of the data and a normal distribution (this code provided)\n",
    "#  This plots a histogram, with the hypothetical normal distribution (with same mean and variance)\n",
    "xs = np.arange(h_co.min(), h_co.max(), 0.1)\n",
    "fit = stats.norm.pdf(xs, np.mean(h_co), np.std(h_co))\n",
    "plt.plot(xs, fit, label='Normal Dist.', lw=4)\n",
    "plt.hist(h_co, normed=True, label='Actual Data');\n",
    "plt.title('Cognitive Science - Height Data')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0a13e9243275b761a9e66e296d2d16a2",
     "grade": false,
     "grade_id": "cell-43e7e03795d82943",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# CS data: plot the comparison of the data and a normal distribution (this code provided)\n",
    "#  This plots a histogram, with the hypothetical normal distribution (with same mean and variance)\n",
    "xs = np.arange(h_cs.min(), h_cs.max(), 0.1)\n",
    "fit = stats.norm.pdf(xs, np.mean(h_cs), np.std(h_cs))\n",
    "plt.plot(xs, fit, label='Normal Dist.', lw=4)\n",
    "plt.hist(h_cs, normed=True, label='Actual Data');\n",
    "plt.title('Computer Science - Height Data')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "68033a51cb0fb99a4fadf1cb4d55adc8",
     "grade": false,
     "grade_id": "part5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 5: Data Analysis\n",
    "\n",
    "Now let's analyze the data, to address our research question.\n",
    "\n",
    "For the purposes of this analysis, let's assume we need at least 75 students per major to analyze the height data. \n",
    "\n",
    "This means we are only going to use data from people who wrote 'COGSCI' or 'COMPSCI' as their major. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "38e42ac23bb8c77356cfcbcdef473970",
     "grade": false,
     "grade_id": "5a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5a) Pull out the data we are going to use:\n",
    "#  Save the height data for all 'COGSCI' majors to a variable called 'h_co'\n",
    "#  Save the height data for all 'COMPSCI' majors to a variable called 'h_cs'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0056888b291f3783a6abe7b8606bebd6",
     "grade": true,
     "grade_id": "5a_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(h_co)\n",
    "assert np.all(h_cs)\n",
    "\n",
    "assert len(h_co) == 179\n",
    "assert len(h_cs) == 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "298436dfb974f61909065db672e79f96",
     "grade": false,
     "grade_id": "5b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5b) What is the average (mean) height for students from each major?\n",
    "#  Save these values to 'avg_h_co' for cogs students, and 'avg_h_cs' for cs students. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52d7e6e320372c73934dd278d9fc91f3",
     "grade": true,
     "grade_id": "5b_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert avg_h_co\n",
    "assert avg_h_cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "02901d3f841cd12a9a19ab7878dfa788",
     "grade": false,
     "grade_id": "print_avgs",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Print out the average heights - this code provided\n",
    "print('Average height of cogs majors is \\t {:2.2f} inches'.format(avg_h_co))\n",
    "print('Average height of cs majors is \\t\\t {:2.2f} inches'.format(avg_h_cs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc8353ba524b264080920e0ca1ac2716",
     "grade": false,
     "grade_id": "ttest_instr",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Based on the cell above, it looks like there might indeed be a difference in the average height for students in cogs vs cs majors. \n",
    "\n",
    "Now we want to statistically test this difference. To do so, we will use a t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "738581f526b8553a8d11bb69b9b33645",
     "grade": false,
     "grade_id": "5c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5c) Use a t-test ('ttest_ind' function) to compare the two height distributions ('h_co' vs 'h_cs')\n",
    "#  'ttest_ind' returns a t-statistic, and a p-value. Save these outputs to 't_val' and 'p_val' respectively. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff4b11f597f49c7a13d7ef5d0595284f",
     "grade": true,
     "grade_id": "5c_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert t_val\n",
    "assert p_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ca155709bc8b052739f2ce36951a1a14",
     "grade": false,
     "grade_id": "print_p",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if statistical test passes significance, using an alpha value of 0.01. This code provided.\n",
    "if p_val < 0.01:\n",
    "    print('Data Science accomplished, there is a significant difference!')\n",
    "else:\n",
    "    print('There is NOT a significant difference!')\n",
    "    \n",
    "# Editorial note:\n",
    "#  Chasing signitificant p-values as the goal itself is not actually a good way to do data (or any) science :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f43329d1a2bf5ada92f7205cc41c04e",
     "grade": false,
     "grade_id": "break",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Note: this test should pass significance. If it doesn't, double check your code up until this point.\n",
    "\n",
    "So - we've reached a conclusion! We're done right!?\n",
    "\n",
    "Nope. We have a first pass analysis, and an interim conclusion that happens to follow our hypothesis. \n",
    "\n",
    "Now let's try to break it. \n",
    "\n",
    "#### Let's explore some more\n",
    "\n",
    "You should always interogate your findings, however they come out. What could be some alternate explanations, that would change our interpretations of the current analyses?\n",
    "\n",
    "In this case, we should be worried about confounding variables. We want to be able to say whether height relates to major specifically, but it could be the case that some other variable, that happens to differ between majors, better explains the differences in height. \n",
    "\n",
    "In this case, we also have data on gender. Let's check if differences in the gender ratio of the two majors can explain the difference in height. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5a5f589daeb38db1046f96ddb56b4158",
     "grade": false,
     "grade_id": "5d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5d) Using 'value_counts' from pandas, extract the number of 'male' and 'female', separately for cogs and cs students. \n",
    "#  To do so, select from the df each major, separately, extract the gender column, and use the 'value_counts' method.\n",
    "#  Save the counts for each gender for 'COGSCI' majors to a variable called 'g_co'\n",
    "#  Save the counts for each gender for 'COMPSCI' majors to a variable called 'g_cs'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7a17a3f82a8137b2c47e4c39d00da1ba",
     "grade": true,
     "grade_id": "5d_ans",
     "locked": true,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(g_co)\n",
    "assert np.all(g_cs)\n",
    "\n",
    "assert g_co[0] == 93\n",
    "assert g_cs[1] == 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "817599ae22983908200e883c6916fbcb",
     "grade": false,
     "grade_id": "5e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5e) What is the ratio of women in each major? \n",
    "#  By ratio, we mean the proportion of students that are female, as a ratio\n",
    "#   This will be value between 0.0 and 1.0, calculated as #F / (#M + #F) - done separately for each major\n",
    "#  You can use the 'g_co' and 'g_cs' variables to calculate these.\n",
    "#  Save the ratio of women in COGSCI to a variable 'r_co'\n",
    "#  Save the ratio of women in COMPSCI to a variable 'r_cs'\n",
    "#  Note: keep these numbers as ratios (they should be decimal numbers, less than 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "651210d5156160e90257cdda9bf181eb",
     "grade": true,
     "grade_id": "5e_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert r_co\n",
    "assert r_cs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bf7ccccc44f78653927f8b9836a0419b",
     "grade": false,
     "grade_id": "cell-22867438369c5a91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Make sure you print out and check the values of these ratios. They seem pretty different.\n",
    "\n",
    "We can actually ask, using a chi-squared test, whether this difference in gender-ratio between the majors is signficantly different.\n",
    "\n",
    "Code to do this is provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2ddcbe4d963e9cbaba470fe557b1a4e0",
     "grade": false,
     "grade_id": "cell-9b13cd3bd898610e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run a chisquared test of the difference of ratios of categorical data between groups\n",
    "chisq, p_val_chi = stats.chisquare(np.array([g_co.values, g_cs.values]), axis=None)\n",
    "\n",
    "if p_val_chi < 0.01:\n",
    "    print('There is a significant difference in ratios!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "95773c13eaa75f7641bc4d5a837a5947",
     "grade": false,
     "grade_id": "5f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5f) Create a new dataframe, called 'df2', which only includes data from 'COGSCI' and 'COMPSCI' majors.\n",
    "#  Hint: you can do this using the or operater '|', with loc. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb88123936d978fd57235ab7fd6bd7fa",
     "grade": true,
     "grade_id": "5f_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df2, pd.DataFrame)\n",
    "assert df2.shape == (344, 10)\n",
    "assert set(df2['major']) == set(['COGSCI', 'COMPSCI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a1da208a7d91c77edde0e409e150a5e3",
     "grade": false,
     "grade_id": "5g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5g) Another way to look at these kinds of comparisons is pivot tables. \n",
    "#  Use the pandas 'pivot_table' method to create pivot table, assign it to a variable 'pv'\n",
    "#  Set the values as'height', and the indices as 'gender' and 'major' in the pivot table.\n",
    "#  Make sure you do this using 'df2'. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0079dc60a3c1204ef589a4a788b2dc67",
     "grade": true,
     "grade_id": "5g_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(pv)\n",
    "assert isinstance(pv.index, pd.MultiIndex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b04f2e70815689da3af7b89cb448f92e",
     "grade": false,
     "grade_id": "print_pv",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Print out the pivot table you just created. \n",
    "#  Compare the average height values, split up by major and gender.\n",
    "#  Does it look like there are differences in heights by major, when spit up by major?\n",
    "pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recap where we are:\n",
    "- Our initial hypothesis suggested there is a significant difference between heights of people in different majors. \n",
    "- However, further analyses suggested there may be a confounding variable, as there is also a significantly different gender balance between majors. \n",
    "\n",
    "Checking the average height, per major, split up by gender, suggests there may not be a difference between major, other than what is explained by gender. \n",
    "\n",
    "Now we want to statistically ask this question: is there still a different in height between majors, when controlling for differences in gender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6591064f748020ebc0800642e09a18ac",
     "grade": false,
     "grade_id": "lm_instr",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Linear Models\n",
    "\n",
    "For the following question you will need to make some linear models, using Ordinary Least Squares (OLS).\n",
    "\n",
    "There is more than one way to do this in Python. For the purposes of this assignment, you must use the method that is outlined in the 'LinearModels' Tutorial, using patsy, and statsmodels. \n",
    "\n",
    "That is: \n",
    "- Create design matrices with 'patsy.dmatrices'\n",
    "- Iniliaize an OLS model with 'sm.OLS'\n",
    "- Fit the OLS model\n",
    "- Check the summary for results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "059502dea0fbc74c36d59e30fe10e5dc",
     "grade": false,
     "grade_id": "5h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5h) Create a linear model to predict height from major (using df2 as data).\n",
    "#  Use patsy.dmatrices to create the design matrices, calling the outputs 'outcome_1', 'predictors_1'\n",
    "#  Create an OLS model (sm.OLS) using 'outcome_1' and 'predictors_1'. Call it 'mod_1'.\n",
    "#  Fit the model, assigning it to 'res_1'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95fa31b6c786eb01b84704536d41ce28",
     "grade": true,
     "grade_id": "5h_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(outcome_1, patsy.design_info.DesignMatrix)\n",
    "assert isinstance(predictors_1, patsy.design_info.DesignMatrix)\n",
    "assert isinstance(mod_1, sm.regression.linear_model.OLS)\n",
    "assert isinstance(res_1, sm.regression.linear_model.RegressionResultsWrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60838c1d7fea9c0f6b34cee79d2af426",
     "grade": false,
     "grade_id": "print_lm1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Print out the summary results of the model fitting\n",
    "print(res_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f54da0227f69a8b854dc495c89fc2ec9",
     "grade": false,
     "grade_id": "5i",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5i) Based on the model you ran above (using alpha value of 0.01), does major significantly predict height?\n",
    "#  Set your answer as a boolean (True / False) to a variable called 'lm_1'.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8481f4d984be26873826faedcf8d2937",
     "grade": true,
     "grade_id": "5i_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(lm_1, bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "953ef0065161f42427353f8529e0c91f",
     "grade": false,
     "grade_id": "5j",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5j) Create a linear model to predict height from both major and gender (using df2 as data).\n",
    "#  Use patsy.dmatrices to create the design matrices, calling the outputs 'outcome_2', 'predictors_2'\n",
    "#  Create an OLS model (sm.OLS) using 'outcome_2' and 'predictors_2'.  Call it 'mod_2'.\n",
    "#  Fit the model, assigning it to 'res_2'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cba278f597e93ddf5c843ff2dc5b50cd",
     "grade": true,
     "grade_id": "5j_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(outcome_2, patsy.design_info.DesignMatrix)\n",
    "assert isinstance(predictors_2, patsy.design_info.DesignMatrix)\n",
    "assert isinstance(mod_2, sm.regression.linear_model.OLS)\n",
    "assert isinstance(res_2, sm.regression.linear_model.RegressionResultsWrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f50ad244b3bd379017fda0dcb36e7ba",
     "grade": false,
     "grade_id": "print_lm2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Print out the results \n",
    "print(res_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cc5e5e06bbe035278910f72458ca8e0f",
     "grade": false,
     "grade_id": "5k",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 5k) Based on the model you ran above (using alpha value of 0.01), does major significantly predict height?\n",
    "#  Set your answer as a boolean (True / False) to a variable called 'lm_2'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "af4501bf03997d756415f9db850aec6a",
     "grade": true,
     "grade_id": "5k_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(lm_2, bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bc97531a934b341ac4cefb4a2e7edac9",
     "grade": false,
     "grade_id": "part6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 6: Discussion & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "69ec27e96947fb429448f658b79dc02d",
     "grade": false,
     "grade_id": "6a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 6a) Set a boolean variables, called 'ans', as True or False as the answer to the following question:\n",
    "#  We have evidence supporting our research question:\n",
    "#    People in different majors have systematically different heights (and this difference can be tied to their major).\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bc00ae7fde26311988927a17d997830d",
     "grade": true,
     "grade_id": "6a_ans",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ans, bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c82f387fa1c4ec8b4df3debeab0f370f",
     "grade": false,
     "grade_id": "cell-e32a03e2cb2725bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 6b) Write a short response (1-2 sentence) summarizing the results.\n",
    "#  Did we support our hypothesis? Why or why not? What turned out to be the finding(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9e7d93c0b30ca1c4aaa296c87a7c5fbf",
     "grade": true,
     "grade_id": "cell-429b1246a4716b07",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "89155458eb98725549f1ac2fa288c4a1",
     "grade": false,
     "grade_id": "other_parts",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Parts 7 & 8: Other Stuff - OPTIONAL!\n",
    "\n",
    "These parts of the assignment (the rest of it) are completely OPTIONAL, and are ungraded.\n",
    "\n",
    "The next couple sections break from the project narrative we've using above, and briefly explores some other topics, approaches and techniques that have (or will) be addressed in the class, and may be useful for you projects. \n",
    "\n",
    "This section is still set up like an assignment, asking you to answer questions to practice working with these methods, with the solutions posted later, but all tests for this section are public.\n",
    "\n",
    "There are example of using these methods in the Tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0577da9e33544a94b742f827c71f8611",
     "grade": false,
     "grade_id": "imports_2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# You will need the following functions for the last section of the assignment\n",
    "#  You should not need to import any other functions\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import whiten\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acc71d469501c618a5d67527e155982e",
     "grade": false,
     "grade_id": "part7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 7: Clustering\n",
    "\n",
    "Suppose we have reason to believe there are distinct clusters of students in the class. However, we do not know which students are in which group, nor the boundaries that define the groups. \n",
    "\n",
    "This is a clustering problem - here you will use KMeans to dry and find the clusters from the data. \n",
    "\n",
    "See an example of how to use sklearn, and specifically KMeans, for clustering in the 'Clustering' notebook in the Tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b0a39897683146694d02b27452a731bb",
     "grade": false,
     "grade_id": "cell-1bf059baf3355cc2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe, to work with here, and drop any empty data in columns we're using\n",
    "df3 = df.copy(deep=True)\n",
    "df3.dropna(subset=['age', 'weight', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35b49ce1bce8d684bc799e8640917cee",
     "grade": false,
     "grade_id": "7_load",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# For convenience, and consistency, we're providing this code to pull out the required data\n",
    "d1 = df3[df3['major'] == 'COGSCI']['weight'].values\n",
    "d2 = df3[df3['major'] == 'COGSCI']['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0dc9face863d088e500004c4774d9521",
     "grade": false,
     "grade_id": "7a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 7a) For both 'd1', and 'd2' (separately) use the 'whiten' function to whiten the data. \n",
    "#  Save the outputs to 'd1w', and 'd2w' repectively. \n",
    "#  Note: look into what this function does, and why you might want or need to do it. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e16a03d7f4312ac28f2d19783e10258",
     "grade": true,
     "grade_id": "7a_ans",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(d1w)\n",
    "assert np.all(d2w)\n",
    "\n",
    "assert round(np.var(d1w)) == 1\n",
    "assert round(np.var(d2w)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a22b39797180e85d0ffe86f202c1aa89",
     "grade": false,
     "grade_id": "7b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 7b) Initialize a Kmeans model object. Call it 'km'.\n",
    "#  Initialize it with 'n_clusters' of 2, and 'random_state' of 42.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ddca5dcaf162d526ed6598173168d174",
     "grade": true,
     "grade_id": "7b_ans",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(km, KMeans)\n",
    "\n",
    "assert km.n_clusters == 2\n",
    "assert km.random_state == 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d8d9b7cc05cab6b096c68c1c7cc3209d",
     "grade": false,
     "grade_id": "7_comb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# For convenience, and consistency, we're providing this code to combine the data into required format.\n",
    "cl_dat = np.array([d1w, d2w]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6bf2ec4970fa7d25062cf2c379e3f442",
     "grade": false,
     "grade_id": "7c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 7c) Use the 'fit' method of the KMeans object (km) to fit the data ('cl_dat').\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c1a444b6fe4b2d119a4bf129bea17b86",
     "grade": true,
     "grade_id": "7c_ans",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.any(km.labels_)\n",
    "assert sum(km.labels_) == 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "20f22a38277facd5c4fbdea4a803b56f",
     "grade": false,
     "grade_id": "7_plt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's check out our clusters (this code provided).\n",
    "plt.scatter(d1, d2, c=km.labels_);\n",
    "plt.xlabel('Weight');\n",
    "plt.ylabel('Age');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b35f09913b3d0a88b730b34615b72e78",
     "grade": false,
     "grade_id": "cell-916208de320f403d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Editorial note:\n",
    "- It does not appear, for this data, that there are particular clusters (or at least not that our current KMeans approach is picking up), but that's fine, we can consider this to have been an exploratory analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "276ec8909f37421b04df85d6c70e3299",
     "grade": false,
     "grade_id": "part8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 8: Dimensionality Reduction\n",
    "\n",
    "Sometimes we have data that have many dimensions, perhaps too many to deal with, and so we might need to try and use dimensionality reduction: that is to try and find a lower dimensional space that captures as much of the information as we can from the original, high-dimensional, dataset. \n",
    "\n",
    "As an example, in our data, we have height and weight that are quite correlated, and we could use Principal Components Analysis (PCA), in order to try and capture the most information about a persons' height and weight in a single number - projecting this 2D data down into 1 dimension. \n",
    "\n",
    "See an example of how to use sklearn, and specifcally PCA, for dimensionality reduction in the 'Dimensionality Reduction' notebook in the Tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28ad3459f0343228bc6438c0ed323f18",
     "grade": false,
     "grade_id": "8_plot_1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check out the height vs. weight data\n",
    "plt.plot(df3['height'].values, df3['weight'].values, '.')\n",
    "plt.xlabel('Height');\n",
    "plt.ylabel('Weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "91c2fcc3a2aa3750215eeb886326c6d0",
     "grade": false,
     "grade_id": "8_load",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# For convenience, and consistency, we're providing this code to pull out the required data\n",
    "d1_h = df3['height'].values\n",
    "d2_w = df3['weight'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "032a0a7acdf15eb8b76e18109e098eb9",
     "grade": false,
     "grade_id": "8a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 8a) Initialize a PCA object. Call it 'dr'. \n",
    "#  Initialize it with 'n_components' of 1, and 'whiten' as True.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56da601a176e17cd933d6f49a5fbd410",
     "grade": true,
     "grade_id": "8a_ans",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(dr, PCA)\n",
    "\n",
    "assert dr.n_components == 1\n",
    "assert dr.whiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f41c07d00ddbb57eb0731c585ef02c2a",
     "grade": false,
     "grade_id": "8_comb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# For convenience, and consistency, we're providing this code to combine the data into required format\n",
    "dr_dat = np.array([d1_h, d2_w]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "da1eaad3149f8ae32d518046514f0c5c",
     "grade": false,
     "grade_id": "8b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 8b) Use the 'fit_transform' method of the PCA object (dr) on the data ('dr_dat')\n",
    "#  This method fits the dimensionality reduction model, and then transforms the data with it. \n",
    "#  Save the output (the transformed data) to 'out'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bbab34084fb88588d4fd1fbdac630078",
     "grade": true,
     "grade_id": "8b_ans",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e46af3961cfc45200f8c852aef1911ce",
     "grade": false,
     "grade_id": "8_plot_2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check the transformed data (this code provided)\n",
    "#  Since this data is now 1D, the x-axis is just the index number of each data point\n",
    "#  Now, for each student, we have a (whitened) single number representing combined height & weight \n",
    "plt.plot(out, '.');\n",
    "plt.xlabel('Subject Number');\n",
    "plt.ylabel('PC1');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
